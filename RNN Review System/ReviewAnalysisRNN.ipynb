{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Review Analysis using RNN\n",
    "\n",
    "Sentiment Analysis of movie reviews using Recurrent Neural Networks and LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reviews = ''\n",
    "labels = ''\n",
    "\n",
    "with open('data/reviews.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "    \n",
    "with open('data/labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Positive Review-->\n",
      "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n"
     ]
    }
   ],
   "source": [
    "print ('Sample Positive Review-->')\n",
    "print (reviews.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Negative Review-->\n",
      "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  \n"
     ]
    }
   ],
   "source": [
    "print ('Sample Negative Review-->')\n",
    "print (reviews.split('\\n')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels.split('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Some data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR REVIEWS\n",
      "Total words : 6347388\n",
      "Total characters : 33678267\n",
      "Unique words : 74073\n",
      "Unique characters: 29\n"
     ]
    }
   ],
   "source": [
    "total_words = len(reviews.split())\n",
    "total_characters = len(reviews)\n",
    "unique_words = len(set(reviews.split()))\n",
    "unique_characters = len(set(reviews))\n",
    "\n",
    "print ('FOR REVIEWS')\n",
    "print (\"Total words :\", total_words)\n",
    "print (\"Total characters :\", total_characters)\n",
    "print (\"Unique words :\", unique_words)\n",
    "print (\"Unique characters:\", unique_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
    "reviews = all_text.split('\\n')\n",
    "labels = labels.split('\\n')\n",
    "\n",
    "all_text = ' '.join(reviews)\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-52fb1a943ed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mpositive_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mtotal_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(len(reviews)):\n",
    "    if(labels[i] == 'positive'):\n",
    "        for word in reviews[i].split():\n",
    "            positive_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "    else:\n",
    "        for word in reviews[i].split():\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "positive_counts.most_common()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "negative_counts.most_common()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
    "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for word,ratio in pos_neg_ratios.most_common():\n",
    "    pos_neg_ratios[word] = np.log(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
    "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pos_neg_ratios.most_common()[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Encoding words to integers. Buidling a dictionary to convert words to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "\n",
    "reviews_ints = []\n",
    "for each in reviews:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in each.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jc': 16371,\n",
       " 'sensitivity': 8055,\n",
       " 'swooning': 28785,\n",
       " 'lashley': 60296,\n",
       " 'imagines': 11980,\n",
       " 'interviewing': 12397,\n",
       " 'sayonara': 15098,\n",
       " 'maxx': 19869,\n",
       " 'kibbutznikim': 73012,\n",
       " 'gameboys': 46418,\n",
       " 'catastrophic': 14045,\n",
       " 'mainstays': 46419,\n",
       " 'holed': 20645,\n",
       " 'flaws': 1491,\n",
       " 'crying': 2540,\n",
       " 'choronzhon': 46420,\n",
       " 'arora': 46421,\n",
       " 'excoriated': 46422,\n",
       " 'pelting': 46423,\n",
       " 'bigas': 24103,\n",
       " 'whats': 4539,\n",
       " 'spying': 13583,\n",
       " 'dilapidated': 14557,\n",
       " 'obsessives': 64482,\n",
       " 'storage': 13154,\n",
       " 'dizzyingly': 46425,\n",
       " 'blade': 4421,\n",
       " 'viscontian': 55594,\n",
       " 'lockley': 51688,\n",
       " 'declining': 16372,\n",
       " 'terminology': 18839,\n",
       " 'soundless': 67282,\n",
       " 'trois': 21025,\n",
       " 'trellis': 46427,\n",
       " 'origonal': 46428,\n",
       " 'tugging': 19870,\n",
       " 'lever': 18840,\n",
       " 'silicone': 19871,\n",
       " 'assurance': 15686,\n",
       " 'clarrissa': 46429,\n",
       " 'friendliest': 37443,\n",
       " 'shamroy': 32300,\n",
       " 'nra': 26225,\n",
       " 'republics': 46430,\n",
       " 'livelihood': 28500,\n",
       " 'kake': 46431,\n",
       " 'hanson': 11302,\n",
       " 'quota': 19872,\n",
       " 'resulting': 4975,\n",
       " 'xo': 46433,\n",
       " 'sentence': 4089,\n",
       " 'fundamentalism': 21026,\n",
       " 'merritt': 65551,\n",
       " 'essendon': 46434,\n",
       " 'ducks': 14046,\n",
       " 'bicker': 21542,\n",
       " 'towed': 46436,\n",
       " 'obedient': 24104,\n",
       " 'otakus': 28788,\n",
       " 'budgetness': 46437,\n",
       " 'admonition': 46438,\n",
       " 'triton': 14558,\n",
       " 'interestedly': 71755,\n",
       " 'cantaloupe': 37444,\n",
       " 'consistently': 4108,\n",
       " 'midsummer': 28789,\n",
       " 'vays': 37445,\n",
       " 'justify': 4313,\n",
       " 'dasilva': 32301,\n",
       " 'collusive': 46439,\n",
       " 'loathsome': 12767,\n",
       " 'japenese': 32302,\n",
       " 'livia': 28355,\n",
       " 'barefaced': 46440,\n",
       " 'sportcaster': 46441,\n",
       " 'criticized': 7472,\n",
       " 'moody': 4327,\n",
       " 'rockers': 17139,\n",
       " 'organizes': 22383,\n",
       " 'mlk': 26227,\n",
       " 'friendly': 2514,\n",
       " 'karmas': 51031,\n",
       " 'melina': 44044,\n",
       " 'palooka': 57861,\n",
       " 'paranoiac': 26228,\n",
       " 'gibraltar': 46444,\n",
       " 'willingham': 46445,\n",
       " 'archival': 16373,\n",
       " 'indebtedness': 37447,\n",
       " 'slovik': 24118,\n",
       " 'barsat': 52178,\n",
       " 'germinates': 46446,\n",
       " 'stinger': 41944,\n",
       " 'elopement': 46447,\n",
       " 'jaja': 46448,\n",
       " 'constructively': 32306,\n",
       " 'gibbons': 26229,\n",
       " 'fit': 1156,\n",
       " 'drillers': 68469,\n",
       " 'folis': 46450,\n",
       " 'guttenberg': 16374,\n",
       " 'vengeant': 46451,\n",
       " 'nowhere': 1251,\n",
       " 'destructively': 46452,\n",
       " 'dearest': 17939,\n",
       " 'tutors': 26230,\n",
       " 'lacky': 46453,\n",
       " 'wuhl': 18841,\n",
       " 'lorean': 46454,\n",
       " 'indolently': 46455,\n",
       " 'bip': 46456,\n",
       " 'venality': 46457,\n",
       " 'msamati': 37449,\n",
       " 'dumas': 32307,\n",
       " 'humorous': 1961,\n",
       " 'fetchingly': 46459,\n",
       " 'heavyhanded': 65818,\n",
       " 'hinkley': 32308,\n",
       " 'nelsons': 46461,\n",
       " 'presenters': 19873,\n",
       " 'doggerel': 43206,\n",
       " 'sale': 6129,\n",
       " 'whiteclad': 46464,\n",
       " 'principle': 6287,\n",
       " 'corny': 2003,\n",
       " 'cluster': 22384,\n",
       " 'reprises': 13584,\n",
       " 'affectionately': 17940,\n",
       " 'uncalculatedly': 46465,\n",
       " 'moonraker': 32309,\n",
       " 'goten': 46466,\n",
       " 'anarchy': 17941,\n",
       " 'custodian': 32357,\n",
       " 'school': 382,\n",
       " 'abbot': 10878,\n",
       " 'furrowed': 44511,\n",
       " 'revel': 12768,\n",
       " 'gaiman': 14559,\n",
       " 'bullet': 3949,\n",
       " 'lefler': 32310,\n",
       " 'breadth': 21027,\n",
       " 'blooper': 24105,\n",
       " 'conscript': 46470,\n",
       " 'stetner': 46471,\n",
       " 'lighters': 26231,\n",
       " 'golddigger': 46472,\n",
       " 'schmitz': 28792,\n",
       " 'fides': 46473,\n",
       " 'call': 668,\n",
       " 'matkondar': 46474,\n",
       " 'intertwain': 46475,\n",
       " 'archbishop': 37450,\n",
       " 'crabtree': 37530,\n",
       " 'ephemeralness': 69444,\n",
       " 'housesitter': 32312,\n",
       " 'marciano': 64865,\n",
       " 'selfloathing': 46478,\n",
       " 'unclassifiable': 46479,\n",
       " 'laserdisc': 26232,\n",
       " 'delusive': 59033,\n",
       " 'gruveyman': 46481,\n",
       " 'picturised': 35721,\n",
       " 'lectures': 14047,\n",
       " 'ormondroyd': 37451,\n",
       " 'overlooks': 24106,\n",
       " 'commands': 10166,\n",
       " 'defensiveness': 46484,\n",
       " 'repairmen': 66168,\n",
       " 'admitt': 69447,\n",
       " 'comely': 19874,\n",
       " 'memory': 1721,\n",
       " 'splatter': 4253,\n",
       " 'ion': 37452,\n",
       " 'laff': 37453,\n",
       " 'croquet': 46486,\n",
       " 'hulce': 14560,\n",
       " 'tran': 28793,\n",
       " 'lummox': 46046,\n",
       " 'alderson': 46488,\n",
       " 'kansas': 5148,\n",
       " 'kongwon': 46489,\n",
       " 'iota': 17942,\n",
       " 'donating': 26233,\n",
       " 'falsification': 32314,\n",
       " 'wheedon': 46490,\n",
       " 'tightly': 7267,\n",
       " 'blots': 46491,\n",
       " 'kingsley': 8653,\n",
       " 'hearkens': 26234,\n",
       " 'skewed': 15687,\n",
       " 'gollywood': 46492,\n",
       " 'millionth': 43408,\n",
       " 'companyman': 46493,\n",
       " 'elected': 8056,\n",
       " 'horns': 12277,\n",
       " 'overwhelmed': 8966,\n",
       " 'jog': 21028,\n",
       " 'tropics': 46494,\n",
       " 'sewanee': 46495,\n",
       " 'superb': 879,\n",
       " 'giver': 24107,\n",
       " 'vip': 26235,\n",
       " 'poo': 9122,\n",
       " 'rotation': 19875,\n",
       " 'muppet': 5401,\n",
       " 'eg': 10624,\n",
       " 'endearment': 26236,\n",
       " 'lieutenent': 46496,\n",
       " 'neous': 46497,\n",
       " 'hogging': 28794,\n",
       " 'breakups': 46498,\n",
       " 'cat': 1047,\n",
       " 'doel': 46499,\n",
       " 'nambla': 37586,\n",
       " 'defense': 4777,\n",
       " 'bewilders': 37456,\n",
       " 'therin': 69449,\n",
       " 'attanborough': 64869,\n",
       " 'unsuspected': 37457,\n",
       " 'shadowlands': 37595,\n",
       " 'rafael': 16375,\n",
       " 'deyoung': 60312,\n",
       " 'labyrinthine': 17943,\n",
       " 'parasitical': 46902,\n",
       " 'berrymore': 46504,\n",
       " 'mindy': 13155,\n",
       " 'pb': 46506,\n",
       " 'objections': 13786,\n",
       " 'dissipates': 26237,\n",
       " 'bondless': 46508,\n",
       " 'kell': 46509,\n",
       " 'smurfs': 21029,\n",
       " 'meatballs': 21030,\n",
       " 'constipated': 18842,\n",
       " 'discombobulated': 46510,\n",
       " 'conflicts': 4504,\n",
       " 'healing': 8809,\n",
       " 'feign': 32315,\n",
       " 'gutted': 15688,\n",
       " 'hooray': 13297,\n",
       " 'sunroof': 46511,\n",
       " 'maddening': 17140,\n",
       " 'abundantly': 22385,\n",
       " 'tazmanian': 46512,\n",
       " 'shrill': 8658,\n",
       " 'esposito': 15099,\n",
       " 'uranus': 24108,\n",
       " 'legally': 11398,\n",
       " 'laemlee': 46514,\n",
       " 'hermeneutic': 46515,\n",
       " 'michelangleo': 46516,\n",
       " 'southeastern': 37459,\n",
       " 'red': 736,\n",
       " 'choreographies': 46517,\n",
       " 'berlusconi': 62535,\n",
       " 'asshole': 18843,\n",
       " 'empties': 46518,\n",
       " 'videocassette': 37461,\n",
       " 'fleapit': 37462,\n",
       " 'retorted': 46519,\n",
       " 'wrap': 4741,\n",
       " 'atmoshpere': 51040,\n",
       " 'heorine': 46521,\n",
       " 'hitch': 9696,\n",
       " 'maupin': 24109,\n",
       " 'jockhood': 46522,\n",
       " 'sematarty': 46523,\n",
       " 'ville': 37463,\n",
       " 'insulting': 3461,\n",
       " 'murderball': 37464,\n",
       " 'moovies': 28796,\n",
       " 'luna': 15100,\n",
       " 'undressing': 26238,\n",
       " 'dc': 11399,\n",
       " 'workers': 2877,\n",
       " 'mesmerizing': 5974,\n",
       " 'boyle': 5102,\n",
       " 'uneventful': 11613,\n",
       " 'cavepeople': 46524,\n",
       " 'routing': 26239,\n",
       " 'nco': 46526,\n",
       " 'dystopian': 15196,\n",
       " 'hurtle': 46432,\n",
       " 'teases': 17944,\n",
       " 'bo': 3006,\n",
       " 'classified': 9123,\n",
       " 'chaimsaw': 46527,\n",
       " 'piffle': 24110,\n",
       " 'dwells': 14049,\n",
       " 'cults': 13298,\n",
       " 'chematodes': 37466,\n",
       " 'futureworld': 46528,\n",
       " 'contributed': 6702,\n",
       " 'manjayegi': 46529,\n",
       " 'accounting': 19876,\n",
       " 'masquerading': 10167,\n",
       " 'huffs': 46530,\n",
       " 'only': 64,\n",
       " 'marginally': 9924,\n",
       " 'shot': 320,\n",
       " 'alicia': 5096,\n",
       " 'stassard': 46531,\n",
       " 'gooks': 37467,\n",
       " 'skullcap': 46532,\n",
       " 'hotty': 46533,\n",
       " 'pumping': 14561,\n",
       " 'seagle': 73060,\n",
       " 'unavliable': 46534,\n",
       " 'preset': 70975,\n",
       " 'reeeaally': 46535,\n",
       " 'lightflash': 46536,\n",
       " 'storey': 24111,\n",
       " 'perverse': 8178,\n",
       " 'leafs': 37468,\n",
       " 'moderated': 47142,\n",
       " 'lad': 10546,\n",
       " 'contra': 18844,\n",
       " 'frf': 37469,\n",
       " 'pearce': 28799,\n",
       " 'mcraney': 32319,\n",
       " 'supersadlysoftie': 46539,\n",
       " 'chihuahuawoman': 46540,\n",
       " 'dumpy': 21031,\n",
       " 'envied': 32320,\n",
       " 'snuffleupagus': 46541,\n",
       " 'dumbfoundingly': 46542,\n",
       " 'touchable': 46543,\n",
       " 'papaya': 41461,\n",
       " 'kidnapper': 22386,\n",
       " 'robotics': 32321,\n",
       " 'duchy': 37470,\n",
       " 'particular': 825,\n",
       " 'sweaty': 12398,\n",
       " 'astaire': 3389,\n",
       " 'reaction': 2060,\n",
       " 'united': 2312,\n",
       " 'galen': 28800,\n",
       " 'assault': 4701,\n",
       " 'mcdougle': 46545,\n",
       " 'firmware': 46546,\n",
       " 'inaccuracies': 6893,\n",
       " 'brutishness': 46547,\n",
       " 'anecdotes': 17945,\n",
       " 'hissy': 26306,\n",
       " 'songmaking': 60322,\n",
       " 'ripoffs': 19877,\n",
       " 'kasugi': 46550,\n",
       " 'coats': 16377,\n",
       " 'phenomenons': 37677,\n",
       " 'commercially': 12769,\n",
       " 'dvds': 5785,\n",
       " 'reluctance': 18845,\n",
       " 'schmoke': 37680,\n",
       " 'federal': 8485,\n",
       " 'gert': 24112,\n",
       " 'raptors': 18846,\n",
       " 'discontinued': 37471,\n",
       " 'canyons': 24156,\n",
       " 'wellknown': 46554,\n",
       " 'pavlinek': 46555,\n",
       " 'kimmy': 26240,\n",
       " 'cinemax': 12399,\n",
       " 'misportrayed': 46556,\n",
       " 'sustaining': 24113,\n",
       " 'donlan': 23452,\n",
       " 'ladislas': 46558,\n",
       " 'colleagues': 6200,\n",
       " 'guardians': 19878,\n",
       " 'station': 1656,\n",
       " 'antevleva': 46559,\n",
       " 'pogany': 46560,\n",
       " 'unquestionable': 22387,\n",
       " 'orations': 46561,\n",
       " 'blackens': 60324,\n",
       " 'everpresent': 46562,\n",
       " 'mello': 46563,\n",
       " 'vereen': 28742,\n",
       " 'bandido': 46565,\n",
       " 'entertainingly': 23234,\n",
       " 'sociology': 21032,\n",
       " 'infectious': 9925,\n",
       " 'lamp': 12046,\n",
       " 'espy': 64881,\n",
       " 'kelly': 1288,\n",
       " 'code': 2138,\n",
       " 'employees': 8057,\n",
       " 'subsidized': 46566,\n",
       " 'floored': 17946,\n",
       " 'circuited': 37472,\n",
       " 'pangs': 32323,\n",
       " 'kops': 32324,\n",
       " 'uchida': 37473,\n",
       " 'winking': 23747,\n",
       " 'acapella': 37474,\n",
       " 'attracting': 17141,\n",
       " 'backstage': 10396,\n",
       " 'monet': 26241,\n",
       " 'dukesofhazzard': 69463,\n",
       " 'patb': 46568,\n",
       " 'giordano': 26242,\n",
       " 'pooping': 37475,\n",
       " 'fatty': 13585,\n",
       " 'traction': 45287,\n",
       " 'dynamite': 7268,\n",
       " 'italo': 32325,\n",
       " 'lescaut': 46571,\n",
       " 'embarrasing': 37476,\n",
       " 'kuan': 46877,\n",
       " 'millennial': 37477,\n",
       " 'stinkin': 46572,\n",
       " 'inthused': 46573,\n",
       " 'elegance': 9926,\n",
       " 'rousseau': 28801,\n",
       " 'orin': 46574,\n",
       " 'terrifyng': 46575,\n",
       " 'droll': 12339,\n",
       " 'marginalizes': 46576,\n",
       " 'scandanavian': 32327,\n",
       " 'puce': 60328,\n",
       " 'merry': 7373,\n",
       " 'noni': 16379,\n",
       " 'radicalized': 46577,\n",
       " 'pingo': 46578,\n",
       " 'darkend': 46579,\n",
       " 'gurinder': 34560,\n",
       " 'soulfulness': 46753,\n",
       " 'larson': 19879,\n",
       " 'wargames': 13586,\n",
       " 'quoters': 46582,\n",
       " 'estonian': 22432,\n",
       " 'thief': 2974,\n",
       " 'miyazaki': 4919,\n",
       " 'posest': 46584,\n",
       " 'snobbish': 14050,\n",
       " 'allnut': 60686,\n",
       " 'pathological': 15689,\n",
       " 'auctions': 37478,\n",
       " 'mechas': 46587,\n",
       " 'navarre': 46588,\n",
       " 'unilaterally': 37479,\n",
       " 'sitcoms': 7577,\n",
       " 'tunis': 46589,\n",
       " 'deviants': 31740,\n",
       " 'acidic': 21033,\n",
       " 'jost': 32330,\n",
       " 'babyyeah': 27904,\n",
       " 'touchstone': 21034,\n",
       " 'occurring': 9639,\n",
       " 'archivist': 37480,\n",
       " 'soon': 504,\n",
       " 'cemetery': 5975,\n",
       " 'slighter': 32332,\n",
       " 'melenzana': 46592,\n",
       " 'guarded': 9927,\n",
       " 'prescribed': 32333,\n",
       " 'pyschosis': 46593,\n",
       " 'slandered': 46594,\n",
       " 'paramore': 51089,\n",
       " 'therapeutic': 32495,\n",
       " 'fk': 12770,\n",
       " 'overflows': 46596,\n",
       " 'caultron': 64887,\n",
       " 'intenstine': 46597,\n",
       " 'godmother': 11614,\n",
       " 'thembrians': 37483,\n",
       " 'homesteader': 46598,\n",
       " 'outposts': 35822,\n",
       " 'delmer': 32334,\n",
       " 'agoraphobic': 37484,\n",
       " 'affectations': 28803,\n",
       " 'weaklings': 46600,\n",
       " 'truckstops': 46601,\n",
       " 'kipper': 46603,\n",
       " 'titling': 32335,\n",
       " 'mousy': 19925,\n",
       " 'overreact': 46604,\n",
       " 'moviesone': 46605,\n",
       " 'johnr': 46606,\n",
       " 'known': 560,\n",
       " 'asif': 46607,\n",
       " 'foolishness': 17142,\n",
       " 'menzies': 15690,\n",
       " 'irreproachable': 46608,\n",
       " 'dissolve': 19881,\n",
       " 'pigeons': 32336,\n",
       " 'coe': 12771,\n",
       " 'candleshoe': 37485,\n",
       " 'flirtatious': 15102,\n",
       " 'somthing': 46610,\n",
       " 'albums': 9509,\n",
       " 'swims': 19276,\n",
       " 'case': 414,\n",
       " 'stiffs': 26243,\n",
       " 'stradling': 60331,\n",
       " 'physco': 46612,\n",
       " 'audrina': 46613,\n",
       " 'ld': 37486,\n",
       " 'horribly': 2326,\n",
       " 'placeholder': 67283,\n",
       " 'sawahla': 46614,\n",
       " 'brasileiro': 46615,\n",
       " 'harleys': 46616,\n",
       " 'coolness': 11735,\n",
       " 'ricky': 6524,\n",
       " 'younglings': 46617,\n",
       " 'diversion': 12048,\n",
       " 'inside': 982,\n",
       " 'crappiness': 24116,\n",
       " 'manawaka': 33723,\n",
       " 'gas': 2499,\n",
       " 'kelada': 26244,\n",
       " 'khanna': 11723,\n",
       " 'files': 5067,\n",
       " 'underlines': 15691,\n",
       " 'devilishness': 46620,\n",
       " 'boz': 24117,\n",
       " 'ca': 11118,\n",
       " 'smidgeon': 37487,\n",
       " 'cutaways': 26245,\n",
       " 'further': 1012,\n",
       " 'handguns': 26246,\n",
       " 'theoscarsblog': 46621,\n",
       " 'am': 239,\n",
       " 'because': 86,\n",
       " 'jeanane': 46622,\n",
       " 'detroit': 6894,\n",
       " 'gisborne': 46623,\n",
       " 'furbies': 46624,\n",
       " 'ized': 32337,\n",
       " 'consultation': 46625,\n",
       " 'doorknobs': 37488,\n",
       " 'openly': 7818,\n",
       " 'wendt': 9928,\n",
       " 'stapes': 46626,\n",
       " 'wan': 8115,\n",
       " 'boatwoman': 46627,\n",
       " 'bafta': 11724,\n",
       " 'covertly': 37489,\n",
       " 'expressive': 10168,\n",
       " 'lysol': 46628,\n",
       " 'howser': 46629,\n",
       " 'attentions': 11725,\n",
       " 'reenberg': 37448,\n",
       " 'ornament': 32338,\n",
       " 'naaah': 46630,\n",
       " 'capes': 26247,\n",
       " 'kumari': 15692,\n",
       " 'fatal': 3552,\n",
       " 'permissive': 28806,\n",
       " 'nanavati': 22390,\n",
       " 'contraband': 32339,\n",
       " 'tadanobu': 15103,\n",
       " 'swat': 10625,\n",
       " 'uvw': 53076,\n",
       " 'womenadela': 46631,\n",
       " 'kevetch': 69353,\n",
       " 'cagey': 28308,\n",
       " 'stoical': 46632,\n",
       " 'postman': 9923,\n",
       " 'liar': 8486,\n",
       " 'withdrawing': 28807,\n",
       " 'campfest': 46633,\n",
       " 'charlene': 32340,\n",
       " 'fowl': 37492,\n",
       " 'lombard': 9320,\n",
       " 'romps': 17143,\n",
       " 'locas': 46634,\n",
       " 'looped': 21036,\n",
       " 'farrah': 7946,\n",
       " 'moonstruck': 8491,\n",
       " 'intuition': 26248,\n",
       " 'steets': 46635,\n",
       " 'magnified': 24119,\n",
       " 'keener': 13587,\n",
       " 'plotless': 26249,\n",
       " 'mackichan': 46636,\n",
       " 'gum': 10169,\n",
       " 'nibble': 46637,\n",
       " 'damned': 6130,\n",
       " 'doreen': 32341,\n",
       " 'champagne': 16381,\n",
       " 'flattop': 37493,\n",
       " 'soup': 5498,\n",
       " 'otoko': 46638,\n",
       " 'bartlett': 26250,\n",
       " 'naushads': 46639,\n",
       " 'chico': 11726,\n",
       " 'mindedly': 46640,\n",
       " 'commensurate': 46641,\n",
       " 'alden': 22391,\n",
       " 'beef': 9930,\n",
       " 'empathetic': 17947,\n",
       " 'gypped': 30338,\n",
       " 'adjusted': 17948,\n",
       " 'intensities': 46643,\n",
       " 'slurred': 46645,\n",
       " 'illustrate': 8655,\n",
       " 'repercussions': 15693,\n",
       " 'geewiz': 46646,\n",
       " 'bloopers': 17949,\n",
       " 'corigliano': 46647,\n",
       " 'tenants': 9931,\n",
       " 'rrw': 44332,\n",
       " 'stack': 5097,\n",
       " 'claustraphobia': 46649,\n",
       " 'hulking': 16382,\n",
       " 'gayness': 37494,\n",
       " 'gwen': 17877,\n",
       " 'eszterhas': 28808,\n",
       " 'disgraceful': 12049,\n",
       " 'determined': 2885,\n",
       " 'gft': 18847,\n",
       " 'stashed': 31743,\n",
       " 'malaysia': 37872,\n",
       " 'lent': 9932,\n",
       " 'esqe': 32343,\n",
       " 'rehearse': 37496,\n",
       " 'becuz': 28809,\n",
       " 'sweeney': 17144,\n",
       " 'nyqvist': 17950,\n",
       " 'dominick': 8810,\n",
       " 'recently': 1009,\n",
       " 'tortuga': 51065,\n",
       " 'premchand': 32344,\n",
       " 'clarifies': 37497,\n",
       " 'environmental': 9933,\n",
       " 'debrise': 46654,\n",
       " 'rdiger': 21037,\n",
       " 'agitator': 57238,\n",
       " 'alita': 46655,\n",
       " 'cater': 16276,\n",
       " 'yugoslavian': 28810,\n",
       " 'leaderships': 46656,\n",
       " 'ensembles': 36417,\n",
       " 'reasonability': 46657,\n",
       " 'wires': 10397,\n",
       " 'shetty': 18848,\n",
       " 'haan': 46658,\n",
       " 'pentimento': 46659,\n",
       " 'polished': 4818,\n",
       " 'nominating': 26251,\n",
       " 'bruckheimer': 9124,\n",
       " 'handlers': 37884,\n",
       " 'turntable': 32579,\n",
       " 'paquerette': 46662,\n",
       " 'course': 259,\n",
       " 'optimism': 8487,\n",
       " 'invites': 5304,\n",
       " 'ossie': 21038,\n",
       " 'bough': 46663,\n",
       " 'volunteering': 24120,\n",
       " 'dola': 16383,\n",
       " 'twentieth': 9934,\n",
       " 'herculean': 28812,\n",
       " 'careening': 37499,\n",
       " 'masonic': 46664,\n",
       " 'levens': 32345,\n",
       " 'accentuate': 22250,\n",
       " 'minors': 19884,\n",
       " 'rekka': 46665,\n",
       " 'gunslinger': 13588,\n",
       " 'daves': 22392,\n",
       " 'beltrami': 37501,\n",
       " 'rectal': 32346,\n",
       " 'despots': 64897,\n",
       " 'seekers': 19885,\n",
       " 'god': 515,\n",
       " 'talosians': 26253,\n",
       " 'alleyway': 28813,\n",
       " 'krusty': 46667,\n",
       " 'choreographer': 9125,\n",
       " 'suoi': 69474,\n",
       " 'shaku': 46668,\n",
       " 'grime': 32347,\n",
       " 'niccolo': 51673,\n",
       " 'substantively': 46669,\n",
       " 'whedon': 46670,\n",
       " 'hertfordshire': 47362,\n",
       " 'beams': 15128,\n",
       " 'tweedy': 37502,\n",
       " 'glamourise': 37503,\n",
       " 'generally': 1199,\n",
       " 'aborigone': 46672,\n",
       " 'narcotic': 26254,\n",
       " 'miltonesque': 46673,\n",
       " 'choicest': 37504,\n",
       " 'jerrod': 46674,\n",
       " 'conspiratorial': 32349,\n",
       " 'speaker': 9697,\n",
       " 'priestess': 22393,\n",
       " 'shows': 286,\n",
       " 'padre': 46676,\n",
       " 'serb': 24202,\n",
       " 'arbaaz': 32600,\n",
       " 'ivan': 10170,\n",
       " 'percent': 8656,\n",
       " 'extinguishing': 46677,\n",
       " 'outweight': 46678,\n",
       " 'nacional': 46679,\n",
       " 'deathy': 67700,\n",
       " 'immaturely': 63543,\n",
       " 'enforces': 32351,\n",
       " 'gentiles': 46680,\n",
       " 'dumbfounding': 37505,\n",
       " 'gate': 5616,\n",
       " 'grabber': 26255,\n",
       " 'intends': 10171,\n",
       " 'manoven': 37506,\n",
       " 'concoctions': 46681,\n",
       " 'beaches': 12050,\n",
       " 'lithographer': 46682,\n",
       " 'conon': 46683,\n",
       " 'providing': 3709,\n",
       " 'ruck': 37507,\n",
       " 'impressive': 1132,\n",
       " 'character': 104,\n",
       " 'shadows': 3737,\n",
       " 'dts': 37508,\n",
       " 'finery': 37509,\n",
       " 'wrongggg': 46684,\n",
       " 'aaliyah': 46685,\n",
       " 'foresees': 46686,\n",
       " 'exaturated': 57837,\n",
       " 'container': 17951,\n",
       " 'triana': 46687,\n",
       " 'napper': 46688,\n",
       " 'shreds': 12772,\n",
       " 'pearson': 28977,\n",
       " 'unmolested': 60345,\n",
       " 'vengeful': 9321,\n",
       " 'urdhu': 57158,\n",
       " 'tangle': 22466,\n",
       " 'arnis': 46689,\n",
       " 'wen': 22394,\n",
       " 'lallies': 46690,\n",
       " 'urchin': 28817,\n",
       " 'exchanging': 17145,\n",
       " 'heavenlier': 46691,\n",
       " 'paralysis': 26257,\n",
       " 'plainness': 41241,\n",
       " 'mahoney': 13589,\n",
       " 'renny': 11400,\n",
       " 'jethro': 24121,\n",
       " 'jms': 41955,\n",
       " 'steinberg': 26681,\n",
       " 'petronius': 32353,\n",
       " 'linearly': 37511,\n",
       " 'nevertheless': 2156,\n",
       " 'caled': 46693,\n",
       " 'anachronic': 37512,\n",
       " 'westland': 46695,\n",
       " 'nymphomaniac': 14051,\n",
       " 'dru': 37513,\n",
       " 'mal': 26258,\n",
       " 'regulars': 10879,\n",
       " 'teesh': 46696,\n",
       " 'approximates': 32354,\n",
       " 'brigitta': 28988,\n",
       " 'capitaes': 46697,\n",
       " 'gangsterism': 33453,\n",
       " 'shani': 21425,\n",
       " 'cowardly': 8312,\n",
       " 'jamal': 37514,\n",
       " 'doubting': 16385,\n",
       " 'lockett': 37980,\n",
       " 'trendier': 46701,\n",
       " 'paragraphs': 21040,\n",
       " 'mourns': 26259,\n",
       " 'sensuously': 46703,\n",
       " 'martyn': 46704,\n",
       " 'digart': 37515,\n",
       " 'alternativa': 46705,\n",
       " 'dicenzo': 37516,\n",
       " 'thenceforward': 46706,\n",
       " 'brak': 22395,\n",
       " 'circles': 6793,\n",
       " 'perogatives': 51077,\n",
       " 'maneuvers': 26260,\n",
       " 'landscaping': 37517,\n",
       " 'lampoonery': 37518,\n",
       " 'crimes': 3266,\n",
       " 'possesor': 46708,\n",
       " 'rite': 24122,\n",
       " 'untruthful': 46709,\n",
       " 'aishwarya': 19886,\n",
       " 'vangelis': 46710,\n",
       " 'futility': 14052,\n",
       " 'collectors': 14562,\n",
       " 'ans': 24123,\n",
       " 'unsetteling': 46711,\n",
       " 'exeter': 67137,\n",
       " 'bogged': 16386,\n",
       " 'standstill': 28819,\n",
       " 'tacky': 5098,\n",
       " 'definitions': 22396,\n",
       " 'phase': 6794,\n",
       " 'proceeds': 4702,\n",
       " 'hankerchief': 46713,\n",
       " 'project': 1148,\n",
       " 'lurhmann': 46714,\n",
       " 'woodsball': 37520,\n",
       " 'rand': 21041,\n",
       " 'gruntled': 46715,\n",
       " 'wegener': 15104,\n",
       " 'bringleson': 68234,\n",
       " 'reduces': 17146,\n",
       " 'shine': 3951,\n",
       " 'emek': 46716,\n",
       " 'sabotaging': 26261,\n",
       " 'overstay': 26262,\n",
       " 'kindergarten': 14007,\n",
       " 'extravagances': 46717,\n",
       " 'silverstone': 12773,\n",
       " 'many': 109,\n",
       " 'shea': 10172,\n",
       " 'vijay': 13590,\n",
       " 'brightens': 26263,\n",
       " 'valrie': 37521,\n",
       " 'valium': 22397,\n",
       " 'slasher': 1149,\n",
       " 'absalom': 37522,\n",
       " 'swordsmanship': 46719,\n",
       " 'saatchi': 46720,\n",
       " 'bangville': 46722,\n",
       " 'coservationist': 46723,\n",
       " 'lookalikes': 46724,\n",
       " 'ossuary': 46725,\n",
       " 'clarmont': 46726,\n",
       " 'sloppish': 46727,\n",
       " 'lassalle': 17147,\n",
       " 'titains': 67262,\n",
       " 'benshi': 46728,\n",
       " 'inwardly': 26264,\n",
       " 'tlc': 37524,\n",
       " 'creepazoid': 46729,\n",
       " 'tuskegee': 46730,\n",
       " 'dions': 46731,\n",
       " 'reservist': 46732,\n",
       " 'exception': 1375,\n",
       " 'km': 56156,\n",
       " 'bakesfield': 46733,\n",
       " 'tenebra': 46734,\n",
       " 'predict': 5617,\n",
       " 'setpiece': 46735,\n",
       " 'convoy': 32657,\n",
       " 'law': 1119,\n",
       " 'vaulting': 26265,\n",
       " 'kismet': 46737,\n",
       " 'revolutionists': 46738,\n",
       " 'staid': 19888,\n",
       " 'sanata': 60352,\n",
       " 'loutishness': 45027,\n",
       " 'brochure': 26266,\n",
       " 'upa': 28821,\n",
       " 'homerun': 37525,\n",
       " 'gershon': 15694,\n",
       " 'warming': 3952,\n",
       " 'geeze': 46739,\n",
       " 'unjaded': 46740,\n",
       " 'lovehatedreamslifeworkplayfriends': 73428,\n",
       " 'sen': 10627,\n",
       " 'chinnery': 32358,\n",
       " 'heikkil': 46741,\n",
       " 'deere': 32359,\n",
       " 'suprised': 21042,\n",
       " 'yurek': 46744,\n",
       " 'keusch': 24124,\n",
       " 'loyalism': 46745,\n",
       " 'cultivate': 32360,\n",
       " 'wombat': 46746,\n",
       " 'factotum': 65654,\n",
       " 'metamoprhis': 46747,\n",
       " 'ensures': 12051,\n",
       " 'moderator': 26267,\n",
       " 'gleanings': 61562,\n",
       " 'injustise': 46749,\n",
       " 'martyrdom': 25070,\n",
       " 'nominal': 14563,\n",
       " 'locational': 65682,\n",
       " 'ulterior': 17148,\n",
       " 'paget': 15695,\n",
       " 'stoops': 24125,\n",
       " 'serat': 37527,\n",
       " 'monceau': 24126,\n",
       " 'unplug': 46751,\n",
       " 'goodwill': 26268,\n",
       " 'neatest': 46752,\n",
       " 'whistling': 14564,\n",
       " 'imp': 24127,\n",
       " 'canning': 32361,\n",
       " 'veen': 69369,\n",
       " 'aurally': 26269,\n",
       " 'dehumanizing': 26270,\n",
       " 'regional': 15017,\n",
       " 'neecessary': 48358,\n",
       " 'moviehowever': 46754,\n",
       " 'feasibly': 46755,\n",
       " 'asphyxiated': 46756,\n",
       " 'amritlal': 46757,\n",
       " 'privates': 18850,\n",
       " 'gags': 1968,\n",
       " 'declares': 9698,\n",
       " 'agitprop': 28823,\n",
       " 'reorganization': 46758,\n",
       " 'yara': 46759,\n",
       " 'naming': 10628,\n",
       " 'contributors': 19889,\n",
       " 'opportunists': 46760,\n",
       " 'honkong': 46761,\n",
       " 'divya': 22773,\n",
       " 'adelade': 46476,\n",
       " 'viable': 14053,\n",
       " 'gadhvi': 46762,\n",
       " 'causeway': 37531,\n",
       " 'stagnant': 13591,\n",
       " 'macchio': 24129,\n",
       " 'dir': 10173,\n",
       " 'apoligize': 46763,\n",
       " 'goitre': 32362,\n",
       " 'pug': 37532,\n",
       " 'stella': 6525,\n",
       " 'itunes': 28824,\n",
       " 'menalaus': 46764,\n",
       " 'coolish': 46765,\n",
       " 'oskar': 27090,\n",
       " 'expository': 26271,\n",
       " 'thunderous': 26272,\n",
       " 'vandalizes': 46767,\n",
       " 'emblazoned': 32363,\n",
       " 'hayle': 46768,\n",
       " 'delightful': 1889,\n",
       " 'sinuses': 32364,\n",
       " 'holds': 1751,\n",
       " 'dq': 29030,\n",
       " 'mourn': 25119,\n",
       " 'accost': 46769,\n",
       " 'rediscoveries': 64424,\n",
       " 'jeff': 1752,\n",
       " 'dissemination': 37534,\n",
       " 'automatic': 7819,\n",
       " 'southron': 46771,\n",
       " 'exorcism': 12774,\n",
       " 'yokia': 46772,\n",
       " 'travelogue': 16388,\n",
       " 'rutilant': 46773,\n",
       " 'morecambe': 46774,\n",
       " 'verhoven': 37535,\n",
       " 'illustrations': 14565,\n",
       " 'advanced': 4620,\n",
       " 'paltrow': 4461,\n",
       " 'siska': 55306,\n",
       " 'reporters': 12170,\n",
       " 'baldy': 46775,\n",
       " 'cunninghams': 46777,\n",
       " 'chapman': 21043,\n",
       " 'strum': 38128,\n",
       " 'philippe': 10880,\n",
       " 'temporal': 17149,\n",
       " 'savalas': 11728,\n",
       " 'hahahahaha': 28825,\n",
       " 'fakk': 37536,\n",
       " 'tattoe': 59630,\n",
       " 'infatuated': 12776,\n",
       " 'invasive': 37537,\n",
       " 'notrious': 46778,\n",
       " 'ferland': 19890,\n",
       " 'child': 470,\n",
       " 'giaconda': 32366,\n",
       " 'deviously': 37538,\n",
       " 'novella': 12401,\n",
       " 'ludwig': 28826,\n",
       " 'samurais': 24130,\n",
       " 'dabbing': 31274,\n",
       " 'cacophony': 19891,\n",
       " 'quotas': 46779,\n",
       " 'updike': 46780,\n",
       " 'guileless': 37539,\n",
       " 'flyes': 46781,\n",
       " 'euros': 21044,\n",
       " 'oversight': 18851,\n",
       " 'isca': 67234,\n",
       " 'nebraskan': 44899,\n",
       " 'spoke': 4569,\n",
       " 'handshake': 32369,\n",
       " 'vr': 24131,\n",
       " 'spiritualist': 28827,\n",
       " 'ecoleanings': 46783,\n",
       " 'catwalks': 37540,\n",
       " 'undifferentiated': 37541,\n",
       " 'winifred': 60358,\n",
       " 'digressive': 37542,\n",
       " 'cheyenne': 15696,\n",
       " 'yao': 46784,\n",
       " 'believably': 11580,\n",
       " 'suckers': 17150,\n",
       " 'thongs': 46785,\n",
       " 'sumerel': 46786,\n",
       " 'revealled': 46787,\n",
       " 'economist': 37544,\n",
       " 'saviors': 46788,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bromwell high is a cartoon comedy  it ran at the same time as some other programs about school life  such as  teachers   my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers   the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students  when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled          at           high  a classic line inspector i  m here to sack one of your teachers  student welcome to bromwell high  i expect that many adults of my age think that bromwell high is far fetched  what a pity that it isn  t   \n",
      "\n",
      "\n",
      "[21141, 308, 6, 3, 1050, 207, 8, 2139, 32, 1, 171, 57, 15, 49, 81, 5817, 44, 382, 110, 140, 15, 5232, 60, 154, 9, 1, 4977, 5866, 475, 71, 5, 260, 12, 21141, 308, 13, 1978, 6, 74, 2401, 5, 613, 73, 6, 5232, 1, 24646, 5, 1985, 10180, 1, 5827, 1504, 36, 51, 66, 204, 145, 67, 1201, 5232, 20812, 1, 44716, 4, 1, 221, 883, 31, 2991, 71, 4, 1, 5796, 10, 686, 2, 67, 1504, 54, 10, 216, 1, 384, 9, 62, 3, 1407, 3698, 783, 5, 3483, 180, 1, 382, 10, 1213, 13978, 32, 308, 3, 349, 341, 2916, 10, 143, 127, 5, 7760, 30, 4, 129, 5232, 1407, 2329, 5, 21141, 308, 10, 528, 12, 109, 1451, 4, 60, 543, 102, 12, 21141, 308, 6, 227, 4149, 48, 3, 2212, 12, 8, 215, 23]\n"
     ]
    }
   ],
   "source": [
    "print (reviews[0])\n",
    "x = []\n",
    "for i in reviews[0].split():\n",
    "    x.append(vocab_to_int[i])\n",
    "print ('\\n')    \n",
    "print (x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Encoding labels to 0(negative) or 1(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels = np.array([1 if each == 'positive' else 0 for each in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Counting number of zero length reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "len(non_zero_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 1\n",
      "Maximum review length: 2514\n"
     ]
    }
   ],
   "source": [
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
    "labels = np.array([labels[ii] for ii in non_zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seq_length = 300\n",
    "features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "for i, row in enumerate(np.array(reviews_ints)):\n",
    "    features[i, -len(row):] = np.array(row)[:seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0, 21141,   308,\n",
       "            6,     3,  1050,   207,     8,  2139,    32,     1,   171,\n",
       "           57,    15,    49,    81,  5817,    44,   382,   110,   140,\n",
       "           15,  5232,    60,   154,     9,     1,  4977,  5866,   475,\n",
       "           71,     5,   260,    12, 21141,   308,    13,  1978,     6,\n",
       "           74,  2401,     5,   613,    73,     6,  5232,     1, 24646,\n",
       "            5,  1985, 10180,     1,  5827,  1504,    36,    51,    66,\n",
       "          204,   145,    67,  1201,  5232, 20812,     1, 44716,     4,\n",
       "            1,   221,   883,    31,  2991,    71,     4,     1,  5796,\n",
       "           10,   686,     2,    67,  1504,    54,    10,   216,     1,\n",
       "          384,     9,    62,     3,  1407,  3698,   783,     5,  3483,\n",
       "          180,     1,   382,    10,  1213, 13978,    32,   308,     3,\n",
       "          349,   341,  2916,    10,   143,   127,     5,  7760,    30,\n",
       "            4,   129,  5232,  1407,  2329,     5, 21141,   308,    10,\n",
       "          528,    12,   109,  1451,     4,    60,   543,   102,    12,\n",
       "        21141,   308,     6,   227,  4149,    48,     3,  2212,    12,\n",
       "            8,   215,    23],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,    63,     4,     3,\n",
       "          125,    36,    47,  7544,  1395,    16,     3,  4188,   505,\n",
       "           45,    17,     3,   622,   134,    12,     6,     3,  1280,\n",
       "          457,     4,  1723,   207,     3, 10862,  7457,   300,     6,\n",
       "          667,    83,    35,  2116,  1088,  2994,    34,     1,   901,\n",
       "        61156,     4,     8,    13,  5117,   464,     8,  2668,  1723,\n",
       "            1,   221,    57,    17,    58,   796,  1299,   834,   228,\n",
       "            8,    43,    98,   123,  1470,    59,   147,    38,     1,\n",
       "          964,   142,    29,   667,   123,     1, 13710,   410,    61,\n",
       "           95,  1774,   306,   756,     5,     3,   819, 10478,    22,\n",
       "            3,  1727,   635,     8,    13,   128,    73,    21,   233,\n",
       "          102,    17,    49,    50,   618,    34,   684,    85, 29390,\n",
       "        29627,   684,   374,  3351, 11443,     2, 16458,  7953,    51,\n",
       "           29,   108,  3339]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:(20000, 300) \n",
      "Validation set:(2500, 300) \n",
      "Test set: (2500, 300)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "split_idx = int(len(features)*0.8)\n",
    "train_x, val_x = features[:split_idx], features[split_idx:]\n",
    "train_y, val_y = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(val_x)*0.5)\n",
    "val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
    "val_y, test_y = val_y[:test_idx], val_y[test_idx:]\n",
    "\n",
    "print(\"Train set:{}\".format(train_x.shape), \n",
    "      \"\\nValidation set:{}\".format(val_x.shape),\n",
    "      \"\\nTest set: {}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 512\n",
    "lstm_layers = 2\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "n_words = len(vocab_to_int) + 1\n",
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Buidling the RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Defining the placeholder for feeding the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def placeholders():\n",
    "    inputs = tf.placeholder(tf.int32, shape=(None, None), name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, shape=(None), name='targets')\n",
    "    keep_prob = tf.placeholder(tf.float32, name= 'keep_prob')\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Building the embedding lookup matrix to get the embedded vectors to pass to the LSTM cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_embedding(n_words, embed_size, inputs):\n",
    "    embedding_matrix = tf.Variable(tf.random_uniform((n_words, embed_size), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding_matrix, inputs)\n",
    "    \n",
    "    return embedding_matrix, embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Creating LSTM cells for our RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell(lstm_size, lstm_layers, batch_size, keep_prob):\n",
    "    \n",
    "    def build_cell(lstm_size, keep_prob):\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(lstm_layers)])\n",
    "    state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return cell, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Function for returning batches from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_batches(x, y, batch_size=100):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Setting up all variables and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "## Getting input tensors\n",
    "inputs, targets, keep_prob = placeholders()\n",
    "\n",
    "embedding_matrix, embed = create_embedding(n_words, embed_size, inputs)\n",
    "\n",
    "## Creating LSTM Cell\n",
    "cell, initial_state = lstm_cell(lstm_size, lstm_layers, batch_size, keep_prob)\n",
    "\n",
    "## Collect outputs(RNN Forward Pass)\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, embed, initial_state = initial_state)\n",
    "\n",
    "## Predictions\n",
    "predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn = tf.sigmoid)\n",
    "\n",
    "## Cost - Mean Squared Error\n",
    "cost = tf.losses.mean_squared_error(targets, predictions)\n",
    "\n",
    "## Gradient Descent Step - Backpropagation\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "## Calculating accuracy and correct predictions\n",
    "correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), targets)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Training the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 Iteration: 5 Train loss: 0.251\n",
      "Epoch: 0/10 Iteration: 10 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 15 Train loss: 0.251\n",
      "Epoch: 0/10 Iteration: 20 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 25 Train loss: 0.250\n",
      "Val acc: 0.500\n",
      "Epoch: 0/10 Iteration: 30 Train loss: 0.251\n",
      "Epoch: 0/10 Iteration: 35 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 40 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 45 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 50 Train loss: 0.250\n",
      "Val acc: 0.500\n",
      "Epoch: 0/10 Iteration: 55 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 60 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 65 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 70 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 75 Train loss: 0.250\n",
      "Val acc: 0.500\n",
      "Epoch: 0/10 Iteration: 80 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 85 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 90 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 95 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 100 Train loss: 0.250\n",
      "Val acc: 0.500\n",
      "Epoch: 0/10 Iteration: 105 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 110 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 115 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 120 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 125 Train loss: 0.250\n",
      "Val acc: 0.500\n",
      "Epoch: 0/10 Iteration: 130 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 135 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 140 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 145 Train loss: 0.250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6410ee9e4545>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     initial_state: state}\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        for ii, (x, y) in enumerate(generate_batches(train_x, train_y, batch_size), 1):\n",
    "            feed = {inputs: x,\n",
    "                    targets: y,\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state}\n",
    "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
    "            \n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "\n",
    "            if iteration%25==0:\n",
    "                val_acc = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                for x, y in generate_batches(val_x, val_y, batch_size):\n",
    "                    feed = {inputs: x,\n",
    "                            targets: y,\n",
    "                            keep_prob: 1,\n",
    "                            initial_state: val_state}\n",
    "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "            iteration +=1\n",
    "    saver.save(sess, \"checkpoints/sentiment.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Evaluating Accuracy on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    for ii, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
    "        feed = {inputs_: x,\n",
    "                labels_: y[:, None],\n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state}\n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
