{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_text_path = 'data/human_text.txt'\n",
    "output_text_path = 'data/robot_text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_text = get_data(input_text_path)\n",
    "output_text = get_data(output_text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start]\n",
      "oh, thanks !  i'm fine. this is an evening in my timezone\n",
      "how do you feel today ?  tell me something about yourself\n",
      "how many virtual friends have you got ? \n",
      "\n",
      "\n",
      "hi there, how are you !  ?  üòÅüòÅ\n",
      "üòÑ here is afternoon ! \n",
      "my name is rdany, but you can call me dany (the r means robot). i hope we can be virtual friends ! \n"
     ]
    }
   ],
   "source": [
    "print (input_text[:164])\n",
    "print ('\\n')\n",
    "print (output_text[:153])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22526"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = list(x for x in input_text.split())\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in input corpus: 4307\n",
      "Number of unique words in output corpus: 3995\n"
     ]
    }
   ],
   "source": [
    "unique_input = len({word: None for word in input_text.split()})\n",
    "unique_output = len({word: None for word in output_text.split()})\n",
    "\n",
    "print ('Number of unique words in input corpus: {}'.format(unique_input))\n",
    "print ('Number of unique words in output corpus: {}'.format(unique_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–º', 'j', '—É', '√≥', 'üöç', 'üòä', 'üòë', 'o', ']', '—Ç', 'y', 'üëâ', '‚òÄ', 'ÿ∫', 'ÿ¢', '–≤', '3', 'üòù', 'ÿ´', '‚Äô']\n",
      "\n",
      "\n",
      "['–º', 'j', '√≥', 'üçø', '—É', 'üòä', 'o', '…™', ']', 'Àà', '·µª', '—Ç', 'y', 'üçÇ', '‚òÄ', 'üé§', 'ÿ¢', '–≤', '3', 'üòù']\n"
     ]
    }
   ],
   "source": [
    "print (list(set(input_text))[:20])\n",
    "print ('\\n')\n",
    "print (list(set(output_text))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in input corpus: 2363\n",
      "Average number of words in each sentence in input corpus: 9.532797291578502\n"
     ]
    }
   ],
   "source": [
    "sentences_input = input_text.split('\\n')\n",
    "word_counts_input = [len(sentence.split()) for sentence in sentences_input]\n",
    "\n",
    "print ('Number of sentences in input corpus: {}'.format(len(sentences_input)))\n",
    "print ('Average number of words in each sentence in input corpus: {}'.format(np.average(word_counts_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in input corpus: 2363\n",
      "Average number of words in each sentence in input corpus: 9.848074481591198\n"
     ]
    }
   ],
   "source": [
    "sentences_output = output_text.split('\\n')\n",
    "word_counts_output = [len(sentence.split()) for sentence in sentences_output]\n",
    "print ('Number of sentences in input corpus: {}'.format(len(sentences_output)))\n",
    "print ('Average number of words in each sentence in input corpus: {}'.format(np.average(word_counts_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyszMcul/ACGiDmbgZ1ynAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11354dd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "n_groups = 2\n",
    "\n",
    "unique = (unique_input, unique_output)\n",
    "sentences = (len(sentences_input), len(sentences_output))\n",
    " \n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.3\n",
    "opacity = 0.5\n",
    " \n",
    "rects1 = plt.bar(index, unique, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='unique words')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, sentences, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='g',\n",
    "                 label='sentences')\n",
    " \n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Frequencies')\n",
    "plt.xticks(index + bar_width, ('Input Sequence', 'Output Sequence'))\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4308"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = set([word for sentance in input_text.split('\\n') for word in sentance.split(' ')])\n",
    "len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_text = input_text.lower()\n",
    "output_text = output_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example source sequence\n",
      "1\n",
      "\n",
      "\n",
      "Example target sequence\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def extract_character_vocab(data):\n",
    "    special_words = ['<PAD>', '<UNK>', '<GO>',  '<EOS>']\n",
    "\n",
    "    set_words = set([word for sentance in data.split('\\n') for word in sentance.split()])\n",
    "    int_to_vocab = {word_i: word for word_i, word in enumerate(special_words + list(set_words))}\n",
    "    vocab_to_int = {word: word_i for word_i, word in int_to_vocab.items()}\n",
    "\n",
    "    return int_to_vocab, vocab_to_int\n",
    "\n",
    "# Build int2letter and letter2int dicts\n",
    "input_int_to_vocab, input_vocab_to_int = extract_character_vocab(input_text)\n",
    "output_int_to_vocab, output_vocab_to_int = extract_character_vocab(output_text)\n",
    "\n",
    "# Convert characters to ids\n",
    "inputs_ids = [[input_vocab_to_int.get(word, input_vocab_to_int['<UNK>']) for word in sentance.split()] \n",
    "                                                                  for sentance in input_text.split('\\n')]\n",
    "\n",
    "output_ids = [[output_vocab_to_int.get(word, output_vocab_to_int['<UNK>']) for word in sentance.split()] + [output_vocab_to_int['<EOS>']]\n",
    "                                                                         for sentance in input_text.split('\\n')] \n",
    "\n",
    "print(\"Example source sequence\")\n",
    "print(len(inputs_ids[0]))\n",
    "print(\"\\n\")\n",
    "print(\"Example target sequence\")\n",
    "print(len(output_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2301],\n",
       " [2254, 4068, 1211, 2939, 3246, 2216, 243, 2704, 1222, 3203, 2481, 1478],\n",
       " [382, 720, 3517, 805, 1420, 3128, 3513, 2284, 2714, 3155, 848],\n",
       " [382, 3321, 3758, 567, 2526, 3517, 2693, 3128],\n",
       " [243, 2785, 1810, 2395, 3517, 2675, 3513, 3154, 4172, 1581, 3128]]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4311\n",
      "4311\n",
      "3999\n",
      "3999\n"
     ]
    }
   ],
   "source": [
    "print (len(input_vocab_to_int))\n",
    "print (len(input_int_to_vocab))\n",
    "print (len(output_vocab_to_int))\n",
    "print (len(output_int_to_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<UNK>', '<GO>', '<EOS>', 'member', 'korea', 'o.o', 'bot,', \"bo'lardi\", 'creo', 'messenger', 'sedikit', 'day', 'development', 'open-source', 'vzlom', 'fine.do', 'everybody', 'opinion...', 'whaz']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "print (list(input_vocab_to_int.keys())[:20])\n",
    "print (list(input_int_to_vocab.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<UNK>', '<GO>', '<EOS>', 'member', 'find.', 'bot,', 'pidaraz.', 'creo', 'messenger', 'sedikit', 'd√©j√†', 'day', 'leyendo', 'expressiveness', 'üò±üôàüëª', 'development', 'homework.', 'chatbot,', 'todo.']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "print (list(output_vocab_to_int.keys())[:20])\n",
    "print (list(output_int_to_vocab.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_ids(input_text, output_text, input_vocab_to_int, output_vocab_to_int):   \n",
    "    \n",
    "    input_ids = [[input_vocab_to_int[word] for word in sentence.split()]\n",
    "                      for sentence in input_text.split(\"\\n\")]\n",
    "    \n",
    "    output_ids = [[output_vocab_to_int[word] for word in sentence.split()] + [output_vocab_to_int[\"<EOS>\"]]\n",
    "                      for sentence in output_text.split(\"\\n\")]\n",
    "    \n",
    "    return input_ids, output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_ids, output_ids = text_to_ids(input_text, output_text, input_vocab_to_int, output_vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2301], [2254, 4068, 1211, 2939, 3246, 2216, 243, 2704, 1222, 3203, 2481, 1478], [382, 720, 3517, 805, 1420, 3128, 3513, 2284, 2714, 3155, 848], [382, 3321, 3758, 567, 2526, 3517, 2693, 3128], [243, 2785, 1810, 2395, 3517, 2675, 3513, 3154, 4172, 1581, 3128]]\n",
      "[[2330, 3528, 363, 3534, 3271, 1141, 2934, 3214, 3], [3880, 2333, 240, 3826, 1141, 3], [2342, 2795, 240, 1486, 3194, 3271, 2398, 258, 2146, 185, 3587, 3625, 2381, 113, 1012, 471, 2108, 2398, 455, 3502, 530, 1141, 3], [1012, 2383, 3099, 1141, 3194, 546, 750, 2512, 2606, 2670, 2523, 155, 2230, 3], [2918, 2286, 299, 1809, 2544, 2754, 1445, 2119, 1039, 1764, 2179, 3]]\n"
     ]
    }
   ],
   "source": [
    "print (inputs_ids[:5])\n",
    "print (output_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: No GPU found. Please use a GPU to train your neural network.\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "#assert LooseVersion(tf.__version__) in [LooseVersion('1.0.0'), LooseVersion('1.0.1')], 'This project requires TensorFlow version 1.0  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_inputs():\n",
    "    input_data = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "    target_sequence_length = tf.placeholder(tf.int32, (None,), name='target_sequence_length')\n",
    "    max_target_sequence_length = tf.reduce_max(target_sequence_length, name='max_target_len')\n",
    "    source_sequence_length = tf.placeholder(tf.int32, (None,), name='source_sequence_length')\n",
    "    \n",
    "    return input_data, targets, lr, target_sequence_length, max_target_sequence_length, source_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoding_layer(input_data, rnn_size, num_layers,\n",
    "                   source_sequence_length, source_vocab_size, \n",
    "                   encoding_embedding_size):\n",
    "\n",
    "\n",
    "    # Encoder embedding\n",
    "    enc_embed_input = tf.contrib.layers.embed_sequence(input_data, source_vocab_size, encoding_embedding_size)\n",
    "\n",
    "    # RNN cell\n",
    "    def make_cell(rnn_size):\n",
    "        enc_cell = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "        return enc_cell\n",
    "\n",
    "    enc_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size) for _ in range(num_layers)])\n",
    "    \n",
    "    enc_output, enc_state = tf.nn.dynamic_rnn(enc_cell, enc_embed_input, sequence_length=source_sequence_length, dtype=tf.float32)\n",
    "    \n",
    "    return enc_output, enc_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process the input we'll feed to the decoder\n",
    "def process_decoder_input(target_data, vocab_to_int, batch_size):\n",
    "    '''Remove the last word id from each batch and concat the <GO> to the begining of each batch'''\n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)\n",
    "\n",
    "    return dec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer(target_letter_to_int, decoding_embedding_size, num_layers, rnn_size,\n",
    "                   target_sequence_length, max_target_sequence_length, enc_state, dec_input):\n",
    "    # 1. Decoder Embedding\n",
    "    target_vocab_size = len(target_letter_to_int)\n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "\n",
    "    # 2. Construct the decoder cell\n",
    "    def make_cell(rnn_size):\n",
    "        dec_cell = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "        return dec_cell\n",
    "\n",
    "    dec_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size) for _ in range(num_layers)])\n",
    "     \n",
    "    # 3. Dense layer to translate the decoder's output at each time \n",
    "    # step into a choice from the target vocabulary\n",
    "    output_layer = Dense(target_vocab_size,\n",
    "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "\n",
    "\n",
    "    # 4. Set up a training decoder and an inference decoder\n",
    "    # Training Decoder\n",
    "    with tf.variable_scope(\"decode\"):\n",
    "\n",
    "        # Helper for the training process. Used by BasicDecoder to read inputs.\n",
    "        training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,\n",
    "                                                            sequence_length=target_sequence_length,\n",
    "                                                            time_major=False)\n",
    "        \n",
    "        \n",
    "        # Basic decoder\n",
    "        training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                           training_helper,\n",
    "                                                           enc_state,\n",
    "                                                           output_layer) \n",
    "        \n",
    "        # Perform dynamic decoding using the decoder\n",
    "        training_decoder_output = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                                                       impute_finished=True,\n",
    "                                                                       maximum_iterations=max_target_sequence_length)[0]\n",
    "    # 5. Inference Decoder\n",
    "    # Reuses the same parameters trained by the training process\n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        start_tokens = tf.tile(tf.constant([target_letter_to_int['<GO>']], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "\n",
    "        # Helper for the inference process.\n",
    "        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings,\n",
    "                                                                start_tokens,\n",
    "                                                                target_letter_to_int['<EOS>'])\n",
    "\n",
    "        # Basic decoder\n",
    "        inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                        inference_helper,\n",
    "                                                        enc_state,\n",
    "                                                        output_layer)\n",
    "        \n",
    "        # Perform dynamic decoding using the decoder\n",
    "        inference_decoder_output = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                            impute_finished=True,\n",
    "                                                            maximum_iterations=max_target_sequence_length)[0]\n",
    "         \n",
    "\n",
    "    \n",
    "    return training_decoder_output, inference_decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "def seq2seq_model(input_data, targets, lr, target_sequence_length, \n",
    "                  max_target_sequence_length, source_sequence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size, \n",
    "                  rnn_size, num_layers):\n",
    "    \n",
    "    # Pass the input data through the encoder. We'll ignore the encoder output, but use the state\n",
    "    _, enc_state = encoding_layer(input_data, \n",
    "                                  rnn_size, \n",
    "                                  num_layers, \n",
    "                                  source_sequence_length,\n",
    "                                  source_vocab_size, \n",
    "                                  encoding_embedding_size)\n",
    "    \n",
    "    \n",
    "    # Prepare the target sequences we'll feed to the decoder in training mode\n",
    "    dec_input = process_decoder_input(targets, output_vocab_to_int, batch_size)\n",
    "    \n",
    "    # Pass encoder state and decoder inputs to the decoders\n",
    "    training_decoder_output, inference_decoder_output = decoding_layer(output_vocab_to_int, \n",
    "                                                                       decoding_embedding_size, \n",
    "                                                                       num_layers, \n",
    "                                                                       rnn_size,\n",
    "                                                                       target_sequence_length,\n",
    "                                                                       max_target_sequence_length,\n",
    "                                                                       enc_state, \n",
    "                                                                       dec_input) \n",
    "    \n",
    "    return training_decoder_output, inference_decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "train_graph = tf.Graph()\n",
    "# Set the graph to default to ensure that it is ready for training\n",
    "with train_graph.as_default():\n",
    "    \n",
    "    # Load the model inputs    \n",
    "    input_data, targets, lr, target_sequence_length, max_target_sequence_length, source_sequence_length = get_model_inputs()\n",
    "    \n",
    "    # Create the training and inference logits\n",
    "    training_decoder_output, inference_decoder_output = seq2seq_model(input_data, \n",
    "                                                                      targets, \n",
    "                                                                      lr, \n",
    "                                                                      target_sequence_length, \n",
    "                                                                      max_target_sequence_length, \n",
    "                                                                      source_sequence_length,\n",
    "                                                                      len(input_vocab_to_int),\n",
    "                                                                      len(output_vocab_to_int),\n",
    "                                                                      encoding_embedding_size, \n",
    "                                                                      decoding_embedding_size, \n",
    "                                                                      rnn_size, \n",
    "                                                                      num_layers)    \n",
    "    \n",
    "    # Create tensors for the training logits and inference logits\n",
    "    training_logits = tf.identity(training_decoder_output.rnn_output, 'logits')\n",
    "    inference_logits = tf.identity(inference_decoder_output.sample_id, name='predictions')\n",
    "    \n",
    "    # Create the weights for sequence_loss\n",
    "    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        \n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n",
    "\n",
    "\n",
    "def pad_id_sequences(source_ids, source_vocab_to_int, target_ids, target_vocab_to_int, sequence_length):\n",
    "    new_source_ids = [list(reversed(sentence + [source_vocab_to_int['<pad>']] * (sequence_length - len(sentence)))) \\\n",
    "                      for sentence in source_ids]\n",
    "    new_target_ids = [sentence + [target_vocab_to_int['<pad>']] * (sequence_length - len(sentence)) \\\n",
    "                      for sentence in target_ids]\n",
    "\n",
    "    return new_source_ids, new_target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(targets, sources, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "        \n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_targets_lengths = []\n",
    "        for target in pad_targets_batch:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "        \n",
    "        pad_source_lengths = []\n",
    "        for source in pad_sources_batch:\n",
    "            pad_source_lengths.append(len(source))\n",
    "        \n",
    "        yield pad_targets_batch, pad_sources_batch, pad_targets_lengths, pad_source_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Number of Epochs\n",
    "epochs = 20\n",
    "# Batch Size\n",
    "batch_size = 128\n",
    "# RNN Size\n",
    "rnn_size = 256\n",
    "# Number of Layers\n",
    "num_layers = 2\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 15\n",
    "decoding_embedding_size = 15\n",
    "# Learning Rate\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/20 Batch    2/17 - Loss:  2.687  - Validation loss:  2.648\n",
      "Epoch   1/20 Batch    4/17 - Loss:  2.272  - Validation loss:  2.804\n",
      "Epoch   1/20 Batch    6/17 - Loss:  1.093  - Validation loss:  2.413\n",
      "Epoch   1/20 Batch    8/17 - Loss:  0.689  - Validation loss:  2.109\n",
      "Epoch   1/20 Batch   10/17 - Loss:  1.517  - Validation loss:  2.095\n",
      "Epoch   1/20 Batch   12/17 - Loss:  1.591  - Validation loss:  2.033\n",
      "Epoch   1/20 Batch   14/17 - Loss:  1.515  - Validation loss:  2.034\n",
      "Epoch   1/20 Batch   16/17 - Loss:  1.757  - Validation loss:  1.992\n",
      "Epoch   2/20 Batch    2/17 - Loss:  1.948  - Validation loss:  2.027\n",
      "Epoch   2/20 Batch    4/17 - Loss:  1.572  - Validation loss:  2.150\n",
      "Epoch   2/20 Batch    6/17 - Loss:  0.818  - Validation loss:  2.016\n",
      "Epoch   2/20 Batch    8/17 - Loss:  0.619  - Validation loss:  1.973\n",
      "Epoch   2/20 Batch   10/17 - Loss:  1.336  - Validation loss:  1.982\n",
      "Epoch   2/20 Batch   12/17 - Loss:  1.486  - Validation loss:  2.006\n",
      "Epoch   2/20 Batch   14/17 - Loss:  1.420  - Validation loss:  1.967\n",
      "Epoch   2/20 Batch   16/17 - Loss:  1.646  - Validation loss:  1.946\n",
      "Epoch   3/20 Batch    2/17 - Loss:  1.848  - Validation loss:  1.953\n",
      "Epoch   3/20 Batch    4/17 - Loss:  1.502  - Validation loss:  2.032\n",
      "Epoch   3/20 Batch    6/17 - Loss:  0.796  - Validation loss:  2.004\n",
      "Epoch   3/20 Batch    8/17 - Loss:  0.599  - Validation loss:  2.031\n",
      "Epoch   3/20 Batch   10/17 - Loss:  1.320  - Validation loss:  2.006\n",
      "Epoch   3/20 Batch   12/17 - Loss:  1.449  - Validation loss:  2.167\n",
      "Epoch   3/20 Batch   14/17 - Loss:  1.383  - Validation loss:  2.176\n",
      "Epoch   3/20 Batch   16/17 - Loss:  1.664  - Validation loss:  2.018\n",
      "Epoch   4/20 Batch    2/17 - Loss:  1.902  - Validation loss:  2.006\n",
      "Epoch   4/20 Batch    4/17 - Loss:  1.486  - Validation loss:  1.963\n",
      "Epoch   4/20 Batch    6/17 - Loss:  0.780  - Validation loss:  2.026\n",
      "Epoch   4/20 Batch    8/17 - Loss:  0.591  - Validation loss:  2.055\n",
      "Epoch   4/20 Batch   10/17 - Loss:  1.345  - Validation loss:  1.984\n",
      "Epoch   4/20 Batch   12/17 - Loss:  1.417  - Validation loss:  1.943\n",
      "Epoch   4/20 Batch   14/17 - Loss:  1.397  - Validation loss:  1.932\n",
      "Epoch   4/20 Batch   16/17 - Loss:  1.577  - Validation loss:  1.979\n",
      "Epoch   5/20 Batch    2/17 - Loss:  1.730  - Validation loss:  1.904\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-267-314bf56db7f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                  \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                  \u001b[0mtarget_sequence_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargets_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                  source_sequence_length: sources_lengths})\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Debug message updating us on the status of the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Split data to training and validation sets\n",
    "train_source = inputs_ids[batch_size:]\n",
    "train_target = output_ids[batch_size:]\n",
    "valid_source = inputs_ids[:batch_size]\n",
    "valid_target = output_ids[:batch_size]\n",
    "(valid_targets_batch, valid_sources_batch, valid_targets_lengths, valid_sources_lengths) = next(get_batches(valid_target, valid_source, batch_size,\n",
    "                           input_vocab_to_int['<PAD>'],\n",
    "                           output_vocab_to_int['<PAD>']))\n",
    "\n",
    "display_step = 2 # Check training loss after every 20 batches\n",
    "\n",
    "checkpoint = \"best_model.ckpt\" \n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        for batch_i, (targets_batch, sources_batch, targets_lengths, sources_lengths) in enumerate(\n",
    "                get_batches(train_target, train_source, batch_size,\n",
    "                           input_vocab_to_int['<PAD>'],\n",
    "                           output_vocab_to_int['<PAD>'])):\n",
    "            \n",
    "            # Training step\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: sources_batch,\n",
    "                 targets: targets_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: targets_lengths,\n",
    "                 source_sequence_length: sources_lengths})\n",
    "\n",
    "            # Debug message updating us on the status of the training\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                \n",
    "                # Calculate validation cost\n",
    "                validation_loss = sess.run(\n",
    "                [cost],\n",
    "                {input_data: valid_sources_batch,\n",
    "                 targets: valid_targets_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: valid_targets_lengths,\n",
    "                 source_sequence_length: valid_sources_lengths})\n",
    "                \n",
    "                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}  - Validation loss: {:>6.3f}'\n",
    "                      .format(epoch_i,\n",
    "                              epochs, \n",
    "                              batch_i, \n",
    "                              len(train_source) // batch_size, \n",
    "                              loss, \n",
    "                              validation_loss[0]))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, checkpoint)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def source_to_seq(text):\n",
    "    '''Prepare the text for the model'''\n",
    "    sequence_length = 15\n",
    "    text = text.lower()\n",
    "    return [input_vocab_to_int.get(word, input_vocab_to_int['<UNK>']) for word in text.split()] + [input_vocab_to_int['<PAD>']]*(sequence_length-len(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./best_model.ckpt\n",
      "[0 0 0 0 0 0 0]\n",
      "Original Text: How can I be the best ?\n",
      "\n",
      "Source\n",
      "  Word Ids:    [382, 2545, 1067, 487, 3154, 561, 3128]\n",
      "  Input Words: how can i be the best ?\n",
      "\n",
      "Target\n",
      "  Word Ids:       []\n",
      "  Response Words: \n",
      "CPU times: user 9.38 s, sys: 194 ms, total: 9.58 s\n",
      "Wall time: 9.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_sentence = 'How can I be the best ?'\n",
    "text = source_to_seq(input_sentence)\n",
    "\n",
    "checkpoint = \"./best_model.ckpt\"\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    source_sequence_length = loaded_graph.get_tensor_by_name('source_sequence_length:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    \n",
    "    #Multiply by batch_size to match the model's input parameters\n",
    "    answer_logits = sess.run(logits, {input_data: [text]*batch_size, \n",
    "                                      target_sequence_length: [len(text)]*batch_size, \n",
    "                                      source_sequence_length: [len(text)]*batch_size})[0] \n",
    "\n",
    "print(answer_logits)\n",
    "pad = input_vocab_to_int[\"<PAD>\"] \n",
    "\n",
    "print('Original Text:', input_sentence)\n",
    "\n",
    "print('\\nSource')\n",
    "print('  Word Ids:    {}'.format([i for i in text]))\n",
    "print('  Input Words: {}'.format(\" \".join([input_int_to_vocab[i] for i in text])))\n",
    "\n",
    "print('\\nTarget')\n",
    "print('  Word Ids:       {}'.format([i for i in answer_logits if i != pad]))\n",
    "print('  Response Words: {}'.format(\" \".join([output_int_to_vocab[i] for i in answer_logits if i != pad])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
