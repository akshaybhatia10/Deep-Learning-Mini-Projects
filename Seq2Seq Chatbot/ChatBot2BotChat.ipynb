{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_text_path = 'kaggle/human_text.txt'\n",
    "output_text_path = 'kaggle/robot_text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_text = get_data(input_text_path)\n",
    "output_text = get_data(output_text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start]\n",
      "oh, thanks !  i'm fine. this is an evening in my timezone\n",
      "how do you feel today ?  tell me something about yourself\n",
      "how many virtual friends have you got ? \n",
      "\n",
      "\n",
      "hi there, how are you !  ?  üòÅüòÅ\n",
      "üòÑ here is afternoon ! \n",
      "my name is rdany, but you can call me dany (the r means robot). i hope we can be virtual friends ! \n"
     ]
    }
   ],
   "source": [
    "print (input_text[:164])\n",
    "print ('\\n')\n",
    "print (output_text[:153])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in input corpus: 4307\n",
      "Number of unique words in output corpus: 3995\n"
     ]
    }
   ],
   "source": [
    "unique_input = len({word: None for word in input_text.split()})\n",
    "unique_output = len({word: None for word in output_text.split()})\n",
    "\n",
    "print ('Number of unique words in input corpus: {}'.format(unique_input))\n",
    "print ('Number of unique words in output corpus: {}'.format(unique_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['⁄Ü', '*', '‚ñ∏', 'ÿ®', '√±', 'üòä', 'Ÿà', 'üòú', 'i', 'y', '5', 'ü§í', 'üåö', '—á', '‚òÄ', '–∫', '`', '—à', 'ÿØ', '2']\n",
      "\n",
      "\n",
      "['üçù', '⁄Ü', '*', 'ÿ®', '√±', 'üòä', 'Ÿà', 'üòú', 'i', 'y', '‚õÑ', '5', 'üç§', '—á', '‚òÄ', '√º', 'üëå', 'üêï', '–∫', '—à']\n"
     ]
    }
   ],
   "source": [
    "print (list(set(input_text))[:20])\n",
    "print ('\\n')\n",
    "print (list(set(output_text))[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in input corpus: 2363\n",
      "Average number of words in each sentence in input corpus: 9.532797291578502\n"
     ]
    }
   ],
   "source": [
    "sentences_input = input_text.split('\\n')\n",
    "word_counts_input = [len(sentence.split()) for sentence in sentences_input]\n",
    "\n",
    "print ('Number of sentences in input corpus: {}'.format(len(sentences_input)))\n",
    "print ('Average number of words in each sentence in input corpus: {}'.format(np.average(word_counts_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in input corpus: 2363\n",
      "Average number of words in each sentence in input corpus: 9.848074481591198\n"
     ]
    }
   ],
   "source": [
    "sentences_output = output_text.split('\\n')\n",
    "word_counts_output = [len(sentence.split()) for sentence in sentences_output]\n",
    "print ('Number of sentences in input corpus: {}'.format(len(sentences_output)))\n",
    "print ('Average number of words in each sentence in input corpus: {}'.format(np.average(word_counts_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYVdWd7vHvKxBxFrVCEJAhIsqsIM6EgAaCJKhXE+3Y\nko7R2+IYhyhqDKRDX+9tOkk7RKUTL5I4QDS2BoeIRgUjSApEERXBCFqIgqiIdECGX/+xV+FJURNQ\np2pX8X6e5zy1z9p7r70OnFNvrbXX2VsRgZmZWd7s0tANMDMzq4wDyszMcskBZWZmueSAMjOzXHJA\nmZlZLjmgzMwslxxQZjshSZ9K6tzQ7TCrjvw9KLPKSVoCtAY2FRQfEhHvNkyLzHYu7kGZVe8bEbFn\nwePvwklS84ZqmFlT54Ay2waSOkoKSedKehv4Uyo/WtLzkj6W9JKkgQX7dJL0rKQ1kqZJukXSb9O6\ngZLKKhxjiaQT0/Iukq6R9KakVZKmSNqvQltGSnpb0geSriuop5mka9O+ayTNkdQ+rQtJB6flXSWN\nT3W8L+l2SbuldQdImppe14eSZkjy7w2rF36jmW2frwCHAUMktQUeAX4K7AdcCTwgqSRtew8wBzgA\n+Bdg5DYc52LglHS8A4GPgFsrbHM80BUYDNwg6bBUfjlwFjAM2Bv4HvDflRzjRuAQoA9wMNAWuCGt\nuwIoA0rIhjuvBXxewOqFA8qsev+Veg8fS/qvgvIxEbE2Iv4GnA08GhGPRsTmiJgGlALDJB0EHAn8\nKCLWR8R04A/bcPx/Bq6LiLKIWA+MAU6vMLQ4NiL+FhEvAS8BvVP594HrI2JhZF6KiFWFlUsScD7w\ng4j4MCLWAP8KnJk22QC0ATpExIaImBE+cW31xOPnZtU7JSKeLH8iqWNafKdgmw7AGZK+UVDWAnia\n1OuJiLUF65YC7Wt5/A7Ag5I2F5RtIuvNlHuvYPm/gT3TcnvgzRrqLwF2B+ZkWQWAgGZp+d/IQvGJ\ntH5CRNxYy7ab7RD3oMy2T2Ev4h3gNxGxb8Fjj/SLfDnQStIeBdsfVLC8liwggOy8EVloFNb99Qp1\nt4yIZbVo4zvAl2vY5gPgb0D3gvr3iYg9ASJiTURcERGdgW8Cl0saXItjm+0wB5TZjvst8A1JQ9LE\nhJZp8kO7iFhKNtw3VtIXJB0PFPa03gBaSjpZUgvgemDXgvW3A+MkdQCQVCJpRC3b9SvgXyR1UaaX\npP0LN4iIzcB/Aj+X9MV0jLaShqTl4ZIOTkOBq8l6b5sxqwcOKLMdFBHvACPIJhCsJOu5XMXnn69/\nAI4CPgR+DEwq2Hc1MIosTJaR9agKZ/X9B/Aw2RDbGmBWqqs2fgZMAZ4APgF+DexWyXZXA4uBWZI+\nAZ4km3QB0CU9/xSYCfwyIp6u5fHNdoi/qGtWzySNAQ6OiLMbui1meeYelJmZ5ZIDyszMcslDfGZm\nlkvuQZmZWS412S/qHnDAAdGxY8eGboaZmVUwZ86cDyKipKbtmmxAdezYkdLS0oZuhpmZVSBpaW22\n8xCfmZnlkgPKzMxyyQFlZma51GTPQZnZzmPDhg2UlZWxbt26hm6KFWjZsiXt2rWjRYsW27W/A8rM\nGr2ysjL22msvOnbsSMFtQ6wBRQSrVq2irKyMTp06bVcdHuIzs0Zv3bp17L///g6nHJHE/vvvv0O9\nWgeUmTUJDqf82dH/EweUmZnlks9BmVmTM2ZMvusDKC0tZdKkSdx00011X3mRffe732X48OGcfvrp\nRT2OA6oKxXhDNgY76+s2q2/9+vWjX79+Dd2MGm3cuJHmzRsmKjzEZ2a2g5YsWUKPHj22PB8/fjxj\n0l97AwcO5Oqrr6Z///4ccsghzJgxA4BnnnmG4cOHA7Bq1Sq+9rWv0b17d77//e/ToUMHPvjgg2rr\nffPNNxk6dCh9+/blhBNO4PXXX9+qXT179uTjjz8mIth///2ZNCm7mfM555zDtGnTWLduHf/0T/9E\nz549Ofzww3n66exmyRMnTuSb3/wmgwYNYvDgwUQEF110EV27duXEE09kxYoVW45xzTXX0K1bN3r1\n6sWVV15Zd/+oOKDMzIpu48aNzJ49m1/84heMHTt2q/Vjx47l+OOPZ8GCBZx66qm8/fbbNdZ5/vnn\nc/PNNzNnzhzGjx/PqFGjttrmuOOO489//jMLFiygc+fOW8Jx5syZHHvssdx6661IYv78+dx7772M\nHDlyy6y7uXPncv/99/Pss8/y4IMPsnDhQl599VUmTZrE888/D2TB+uCDD7JgwQJefvllrr/++h35\nZ9qKh/jMzIrstNNOA6Bv374sWbJkq/XTp0/n97//PQAnn3wyrVq1qra+Tz/9lOeff54zzjhjS9n6\n9eu32u6EE05g+vTpdOjQgQsuuIAJEyawbNkyWrVqxR577MFzzz3HxRdfDMChhx5Khw4deOONNwA4\n6aST2G+//ba076yzzqJZs2YceOCBDBo0CIB99tmHli1bcu655zJ8+PAtPcK64h6UmdkOat68OZs3\nb97yvOJ3f3bddVcAmjVrxsaNG3e43s2bN7Pvvvsyb968LY/XXnttq/0HDBjAjBkzmDFjBgMHDqSk\npIT777+fE044ocZj77HHHrVq3+zZszn99NOZOnUqQ4cOrfVrqw0HlJnZDmrdujUrVqxg1apVrF+/\nnqlTp27T/gMGDOCee+4B4LHHHuOjjz6qtt69996bTp068bvf/Q7Irtrw0ksvbVVv+/bt+eCDD1i0\naBGdO3fm+OOPZ/z48QwYMADIelh33303AG+88QZvv/02Xbt2rbR9kydPZtOmTSxfvnzLuapPP/2U\n1atXM2zYMH7+859X2oYd4SE+M2ty6ns2aosWLbjhhhvo378/bdu25dBDD92m/X/84x9z1lln0b17\nd4499lgOOuigGuu9++67ueCCC/jpT3/Khg0bOPPMM+ndu/dWdR911FFs2rQJyAJp9OjRHH/88QCM\nGjWKCy64gJ49e9K8eXMmTpy4pbdX6NRTT+VPf/oT3bp146CDDuKYY44BYM2aNYwYMYJ169YREfzs\nZz/bptddE0VEnVaYF/369YsduWHhzjrdemd93da4vfbaaxx22GEN3Yw6U37D1QMOOKChm7LDKvu/\nkTQnImqcY+8hPjMzyyUP8ZmZ5UxlM/12Ru5BmZlZLjmgzMwsl4oeUJKaSXpR0tT0fD9J0yQtSj9b\nFWw7WtJiSQslDSko7ytpflp3k3xdfTOzJq8+elCXAoXfILsGeCoiugBPpedI6gacCXQHhgK/lNQs\n7XMbcB7QJT3q9ttgZmaWO0WdJCGpHXAyMA64PBWPAAam5buAZ4CrU/l9EbEeeEvSYqC/pCXA3hEx\nK9U5CTgFeKyYbTezxmvMM2Pqtr6BdVtfZebNm8e7777LsGHDin6sxqLYs/h+AfwQ2KugrHVELE/L\n7wGt03JbYFbBdmWpbENarli+FUnnA+cDW77oZmb1oyG/QzdkCLz77ufP16yp2/oL6y504IF1d4x5\n8+ZRWlrqgCpQtCE+ScOBFRExp6ptIvuWcJ19UzgiJkREv4joV1JSUlfVmplVa+3atZx88sn07t2b\nHj16MHnyZObMmcNXvvIV+vbty5AhQ1i+PPu7vLLbb3z22WfccMMNTJ48mT59+jB58mTWrl3L9773\nPfr378/hhx/OQw89BGS3wjjttNMYOnQoXbp04Yc//OGWdjz++OMcccQR9O7dm8GDB29pW2X1LFiw\ngP79+9OnTx969erFokWL6vlfrWbF7EEdB3xT0jCgJbC3pN8C70tqExHLJbUBym8ssgxoX7B/u1S2\nLC1XLDczy4XHH3+cAw88kEceeQSA1atX8/Wvf52HHnqIkpISJk+ezHXXXcedd94JfH77jUcffZSx\nY8fy5JNP8pOf/ITS0lJuueUWAK699loGDRrEnXfeyccff0z//v058cQTgay39eKLL7LrrrvStWtX\nLr74Ylq2bMl5553H9OnT6dSpEx9++CEA48aNq7Se22+/nUsvvZTvfOc7fPbZZ1suh5QnRQuoiBgN\njAaQNBC4MiLOlvRvwEjgxvTzobTLw8A9kn4GHEg2GWJ2RGyS9Imko4EXgHOAm4vVbjOzbdWzZ0+u\nuOIKrr76aoYPH06rVq145ZVXOOmkkwDYtGkTbdq02bJ9TbffAHjiiSd4+OGHGT9+PJBdybz8PlGD\nBw9mn332AaBbt24sXbqUjz76iAEDBtCpUyeALbfKqKqeY445hnHjxlFWVsZpp51Gly5d6vhfZcc1\nxJUkbgSmSDoXWAp8CyAiFkiaArwKbAQujIjySB8FTAR2I5sc4QkSZpYbhxxyCHPnzuXRRx/l+uuv\nZ9CgQXTv3p2ZM2dWun1tbr8RETzwwANbXV38hRde+LsLutZ0C4+q6jnssMM46qijeOSRRxg2bBh3\n3HHHlvs85UW9fFE3Ip6JiOFpeVVEDI6ILhFxYkR8WLDduIj4ckR0jYjHCspLI6JHWndRNNUr3JpZ\no/Tuu++y++67c/bZZ3PVVVfxwgsvsHLlyi0BtWHDBhYsWFBtHXvttRdrCmZ3DBkyhJtvvpnyX3cv\nvvhitfsfffTRTJ8+nbfeegtgyxBfVfX89a9/pXPnzlxyySWMGDGCl19+eTteeXH5Wnxm1uRc0XdM\nvR5v/vz5XHXVVeyyyy60aNGC2267jebNm3PJJZewevVqNm7cyGWXXUb37t2rrOOrX/0qN954I336\n9GH06NH86Ec/4rLLLqNXr15s3ryZTp06VXufqZKSEiZMmMBpp53G5s2b+eIXv8i0adOqrGfKlCn8\n5je/oUWLFnzpS1/i2muvLcY/zQ7x7TaqsLPedmJnfd224xp2mvlrdOhQ/7fbqMtp5k2Vb7dhZmZN\njgPKzMxyyQFlZk1CUz1d0Zjt6P+JA8rMGr3Vq1uydu0qh1SORASrVq2iZcuW212HZ/GZWaM3d247\noIx99llZr8ddvbpeD9fotGzZknbt2tW8YRUcUGbW6H32WQtmzepU78f1rNfi8hCfmZnlkgPKzMxy\nyQFlZma55IAyM7NcckCZmVkuOaDMzCyXHFBmZpZLDigzM8slB5SZmeWSA8rMzHLJAWVmZrnkgDIz\ns1xyQJmZWS45oMzMLJccUGZmlksOKDMzyyUHlJmZ5ZIDyszMcskBZWZmueSAMjOzXHJAmZlZLjmg\nzMwslxxQZmaWSw4oMzPLJQeUmZnlkgPKzMxyyQFlZma55IAyM7NcckCZmVkuOaDMzCyXHFBmZpZL\nRQsoSS0lzZb0kqQFksam8v0kTZO0KP1sVbDPaEmLJS2UNKSgvK+k+WndTZJUrHabmVk+FLMHtR4Y\nFBG9gT7AUElHA9cAT0VEF+Cp9BxJ3YAzge7AUOCXkpqlum4DzgO6pMfQIrbbzMxyoGgBFZlP09MW\n6RHACOCuVH4XcEpaHgHcFxHrI+ItYDHQX1IbYO+ImBURAUwq2MfMzJqoop6DktRM0jxgBTAtIl4A\nWkfE8rTJe0DrtNwWeKdg97JU1jYtVyyv7HjnSyqVVLpy5co6fCVmZlbfihpQEbEpIvoA7ch6Qz0q\nrA+yXlVdHW9CRPSLiH4lJSV1Va2ZmTWAepnFFxEfA0+TnTt6Pw3bkX6uSJstA9oX7NYulS1LyxXL\nzcysCSvmLL4SSfum5d2Ak4DXgYeBkWmzkcBDaflh4ExJu0rqRDYZYnYaDvxE0tFp9t45BfuYmVkT\n1byIdbcB7koz8XYBpkTEVEkzgSmSzgWWAt8CiIgFkqYArwIbgQsjYlOqaxQwEdgNeCw9zMysCSta\nQEXEy8DhlZSvAgZXsc84YFwl5aVAj633MDOzpspXkjAzs1xyQJmZWS45oMzMLJccUGZmlksOKDMz\nyyUHlJmZ5ZIDyszMcskBZWZmueSAMjOzXHJAmZlZLjmgzMwslxxQZmaWSw4oMzPLJQeUmZnlkgPK\nzMxyyQFlZma55IAyM7NcckCZmVku1SqgJB1XmzIzM7O6Utse1M21LDMzM6sTzatbKekY4FigRNLl\nBav2BpoVs2FmZrZzqzaggC8Ae6bt9ioo/wQ4vViNMjMzqzagIuJZ4FlJEyNiaT21yczMrMYeVLld\nJU0AOhbuExGDitEoMzOz2gbU74DbgV8Bm4rXHDMzs0xtA2pjRNxW1JZYLox5ZkxDN6HejRk4pqGb\nYI3Uzvh5gfr7zNR2mvkfJI2S1EbSfuWPorbMzMx2arXtQY1MP68qKAugc902x8zMLFOrgIqITsVu\niJmZWaFaBZSkcyorj4hJddscMzOzTG2H+I4sWG4JDAbmAg4oMzMritoO8V1c+FzSvsB9RWmRmZkZ\n23+7jbWAz0uZmVnR1PYc1B/IZu1BdpHYw4ApxWqUmZlZbc9BjS9Y3ggsjYiyIrTHzMwMqOUQX7po\n7OtkVzRvBXxWzEaZmZnV9o663wJmA2cA3wJekOTbbZiZWdHUdojvOuDIiFgBIKkEeBK4v1gNMzOz\nnVttZ/HtUh5Oyapt2NfMzGyb1bYH9bikPwL3puffBh4tTpPMzMxq6AVJOljScRFxFXAH0Cs9ZgIT\nati3vaSnJb0qaYGkS1P5fpKmSVqUfrYq2Ge0pMWSFkoaUlDeV9L8tO4mSdqB12xmZo1ATcN0vwA+\nAYiI30fE5RFxOfBgWledjcAVEdENOBq4UFI34BrgqYjoAjyVnpPWnQl0B4YCv5TULNV1G3Ae0CU9\nhm7TqzQzs0anpoBqHRHzKxamso7V7RgRyyNiblpeA7wGtAVGAHelze4CTknLI4D7ImJ9RLwFLAb6\nS2oD7B0RsyIiyK7/dwpmZtak1RRQ+1azbrfaHkRSR+Bw4AWy0FueVr0HtE7LbYF3CnYrS2Vt03LF\n8sqOc76kUkmlK1eurG3zzMwsh2oKqFJJ51UslPR9YE5tDiBpT+AB4LKI+KRwXeoRRaU7boeImBAR\n/SKiX0lJSV1Va2ZmDaCmWXyXAQ9K+g6fB1I/4AvAqTVVLqkFWTjdHRG/T8XvS2oTEcvT8F359PVl\nQPuC3dulsmVpuWK5mZk1YdX2oCLi/Yg4FhgLLEmPsRFxTES8V92+aabdr4HXIuJnBase5vNbyI8E\nHiooP1PSrpI6kU2GmJ2GAz+RdHSq85yCfczMrImq7f2gngae3sa6jwP+EZgvaV4quxa4EZgi6Vxg\nKdmlk4iIBZKmAK+SzQC8MCI2pf1GARPJzns9lh5mZtaE1faLutssIp4Dqvq+0uAq9hkHjKukvBTo\nUXetMzOzvPPliszMLJccUGZmlksOKDMzyyUHlJmZ5ZIDyszMcskBZWZmueSAMjOzXHJAmZlZLjmg\nzMwslxxQZmaWSw4oMzPLJQeUmZnlkgPKzMxyyQFlZma55IAyM7NcckCZmVkuOaDMzCyXHFBmZpZL\nDigzM8slB5SZmeWSA8rMzHLJAWVmZrnkgDIzs1xyQJmZWS45oMzMLJccUGZmlksOKDMzyyUHlJmZ\n5ZIDyszMcskBZWZmueSAMjOzXHJAmZlZLjmgzMwslxxQZmaWSw4oMzPLJQeUmZnlkgPKzMxyyQFl\nZma55IAyM7NcKlpASbpT0gpJrxSU7SdpmqRF6WergnWjJS2WtFDSkILyvpLmp3U3SVKx2mxmZvlR\nzB7URGBohbJrgKciogvwVHqOpG7AmUD3tM8vJTVL+9wGnAd0SY+KdZqZWRNUtICKiOnAhxWKRwB3\npeW7gFMKyu+LiPUR8RawGOgvqQ2wd0TMiogAJhXsY2ZmTVh9n4NqHRHL0/J7QOu03BZ4p2C7slTW\nNi1XLK+UpPMllUoqXblyZd212szM6l2DTZJIPaKo4zonRES/iOhXUlJSl1WbmVk9q++Aej8N25F+\nrkjly4D2Bdu1S2XL0nLFcjMza+LqO6AeBkam5ZHAQwXlZ0raVVInsskQs9Nw4CeSjk6z984p2MfM\nzJqw5sWqWNK9wEDgAEllwI+BG4Epks4FlgLfAoiIBZKmAK8CG4ELI2JTqmoU2YzA3YDH0sPMzJq4\nogVURJxVxarBVWw/DhhXSXkp0KMOm2ZmZo2AryRhZma55IAyM7NcckCZmVkuOaDMzCyXHFBmZpZL\nDigzM8slB5SZmeWSA8rMzHLJAWVmZrnkgDIzs1xyQJmZWS45oMzMLJccUGZmlksOKDMzyyUHlJmZ\n5ZIDyszMcskBZWZmueSAMjOzXHJAmZlZLjmgzMwslxxQZmaWSw4oMzPLJQeUmZnlkgPKzMxyyQFl\nZma55IAyM7NcckCZmVkuOaDMzCyXHFBmZpZLDigzM8slB5SZmeWSA8rMzHLJAWVmZrnkgDIzs1xy\nQJmZWS45oMzMLJccUGZmlksOKDMzyyUHlJmZ5ZIDyszMcqnRBJSkoZIWSlos6ZqGbo+ZmRVXowgo\nSc2AW4GvA92AsyR1a9hWmZlZMTWKgAL6A4sj4q8R8RlwHzCigdtkZmZFpIho6DbUSNLpwNCI+H56\n/o/AURFxUYXtzgfOT0+7AgvrtaG2Iw4APmjoRpg1Io35M9MhIkpq2qh5fbSkvkTEBGBCQ7fDtp2k\n0ojo19DtMGssdobPTGMZ4lsGtC943i6VmZlZE9VYAuovQBdJnSR9ATgTeLiB22RmZkXUKIb4ImKj\npIuAPwLNgDsjYkEDN8vqlodmzbZNk//MNIpJEmZmtvNpLEN8Zma2k3FAmZlZLjmgdjKSPi1CnR0l\n/UMV63aRdJOkVyTNl/QXSZ3qug1mdUVSO0kPSVok6U1J/5EmZ9W037U7eNyBko6tYl1rSVMlvSTp\nVUmP7sixGgsHlNWFjkClAQV8GzgQ6BURPYFTgY/rqV1m20SSgN8D/xURXYBDgD2BcbXYfYcCChgI\nVBpQwE+AaRHROyK6ATvF9UgdUDup9NfaM5Lul/S6pLvThxNJSyT9v9TjmS3p4FQ+MV3Vo7yO8t7Y\njcAJkuZJ+kGFQ7UBlkfEZoCIKIuIj9L+X5M0U9JcSb+TtGcqH5raNDf1vqam8jGSriw4/iuSOqbl\ns1Nb50m6I12/EUmfShqX/vKcJal1Km8t6cFU/lL5X65V1WM7jUHAuoj4/wARsQn4AfA9SbtL+q6k\nW8o3Tr2agZJuBHZL75u706hC+efqtfQ52z3ts0TSAWm5X/ocdgT+GfhBquOECu1qA5SVP4mIlwva\ncFUamXhZ0tiC8uskvSHpOUn3ln920vH6peUDJC1Jy80k/VtBXf87lVf3u+JISc+nz9BsSXtVVc/2\ncEDt3A4HLiO7AG9n4LiCdatTj+cW4Bc11HMNMCMi+kTEzyusmwJ8I33o/l3S4ZB9MIDrgRMj4gig\nFLhcUkvgP4FvAH2BL9X0IiQdRtZTOy4i+gCbgO+k1XsAsyKiNzAdOC+V3wQ8m8qPABbUUI/tHLoD\ncwoLIuIT4G3g4Kp2iohrgL+lz0D5e6Yr8MuIOAz4BBhVzf5LgNuBn6c6ZlTY5Fbg15KeTsFzIGR/\n5AFdyK5X2gfoK2mApL5k3xftAwwDjqzFaz+X7HN/ZNr+PH0+HL/V7wplw56TgUvT5+hE4G811LNN\nGsX3oKxoZkdEGYCkeWRDdc+ldfcW/KwYOrUWEWWSupL9ZToIeErSGcBuZG/2P6c/xr4AzAQOBd6K\niEWpXb/l8+srVmUwWZj9JdW1G7AirfsMmJqW5wAnpeVBwDmpjZuA1cqu8VhVPWbb6p2I+HNa/i1w\nCTB+eyqKiD9K6gwMJburw4uSegBfS48X06Z7kgXWXsCDEfHfAJJqc2GDrwG9CkZJ9kl1fUblvytW\nk42O/CW18ZO0vqp63trW1+2A2rmtL1jexN+/H6KS5Y2kXrekXchCpUYRsR54DHhM0vvAKcATZGPq\nZxVuK6lPNVVtOX7Ssnw34K6IGF3JPhvi8y/7VXyNFVVXj+0cXgVOLyyQtDdwELAY6EXl78HKVPyS\n6Vafoxr2//udIz4E7gHuScPeA8jes/8nIu6o0ObLqqmqquMLuDgi/lihroFU/7uiokrr2R4e4rOq\nfLvg58y0vISshwHwTaBFWl5D9hfbViQdUTAcsQvZB3wpMItsmKD8/NYekg4BXgc6SvpyqqIwwJaQ\nDcch6QigfNjgKeB0SV9M6/aT1KGG1/cUcEHavpmkfbazHmtangJ2l3QObLkX3b8DE1NvZAnQR9ns\n1PZkQ2vlNkhqUfD8IEnHpOV/4PPRiSV8/jn6XwXbV/c5GlRwDmsv4Mtkw45/JDs/Vn7+tm16/04H\nTpG0W9r+GwXVFR6/MIz/CFxQ/hokHSJpj8rakywE2kg6srxdkppvRz1VckBZVVpJehm4lOwkMWTn\nhr4i6SXgGGBtKn8Z2JROlFacJPFF4A+SXknbbQRuiYiVwHeBe9NxZgKHRsQ6siG9RyTN5e+H2B4A\n9pO0ALgIeAMgIl4lO5/1RKprGtlJ5epcCnxV0nyyob9u21mPNSGpt30qcIakRWTvsXV8PkPvz2RD\nVa+SncecW7D7BOBlSXen5wuBCyW9BrQCbkvlY4H/kFRK1hsp9wfgVFU+SaIvUFrwWflVRPwlIp4g\n61XNTO/l+4G9ImIu2fmhl8hGL/5SUNd4sgB5keyWHeV+lV7X3PR5vYNqekrp3nzfBm5OvxOmkfXI\ntqme6vhSR7aVNKunX0Q0+L1m0vDClRExvKHbYlZbymblTY2IHg3cFCCbAQt8GhHbdQ6sobgHZWZm\nueQelJmZ5ZJ7UGZmlksOKDMzyyUHlJmZ5ZK/qGvWACTtT/adG8gu57QJWJme909TeM12ap4kYdbA\nGusUYLNi8xCfWY5I+ldJFxU8/7+SLpR0YrpQ6GOSFkq6teCK0l/X51eFn7y939o3yxsHlFm+3AmM\nhC2X2TmD7EoBAEeRXZ6pG3AYMCJd1uYaYHC6Knz51T/MGj2fgzLLkYhYLGmNpJ5AB7KrSH+UOkuz\n0m0ZkHQfcHzarRvwfMFV4Z/bqmKzRsgBZZY/vya7TmFHsuuYlavs6tgCHo+If6yXlpnVIw/xmeXP\nA2RXn+4DPFlQfrSkg9LQ37fIekrPk13AtzNsuSp8l/pusFkxuAdlljMRsU7SdOC9iNhcsGo22V1X\nv0wWXA8MZ8GsAAAAbElEQVRHREg6F5ic7nAK2ZW3F9Vro82KwNPMzXIm3TdrHnBKRPw1lZ0IXBQR\npzRo48zqkYf4zHIkTY54k+y80l8buj1mDck9KDMzyyX3oMzMLJccUGZmlksOKDMzyyUHlJmZ5ZID\nyszMcul/ACGiDmbgZ1ynAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119e8d2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "n_groups = 2\n",
    "\n",
    "unique = (unique_input, unique_output)\n",
    "sentences = (len(sentences_input), len(sentences_output))\n",
    " \n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.3\n",
    "opacity = 0.5\n",
    " \n",
    "rects1 = plt.bar(index, unique, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 label='unique words')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, sentences, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='g',\n",
    "                 label='sentences')\n",
    " \n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Frequencies')\n",
    "plt.xticks(index + bar_width, ('Input Sequence', 'Output Sequence'))\n",
    "plt.legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lookup_tables(text):\n",
    "    vocab = set(text.split())\n",
    "    vocab_to_int = copy.copy(CODES)\n",
    "\n",
    "    for v_i, v in enumerate(vocab, len(CODES)):\n",
    "        vocab_to_int[v] = v_i\n",
    "\n",
    "    int_to_vocab = {v_i: v for v, v_i in vocab_to_int.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_text = input_text.lower()\n",
    "output_text = output_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_vocab_to_int, input_int_to_vocab = create_lookup_tables(input_text)\n",
    "output_vocab_to_int, output_int_to_vocab = create_lookup_tables(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4311\n",
      "4311\n",
      "3999\n",
      "3999\n"
     ]
    }
   ],
   "source": [
    "print (len(input_vocab_to_int))\n",
    "print (len(input_int_to_vocab))\n",
    "print (len(output_vocab_to_int))\n",
    "print (len(output_int_to_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<EOS>', '<UNK>', '<GO>', 'gentlemen.', 'despert√©', 'va', 'ping', 'env√≠a', 'emotions.', 'twilight', 'hopkins', 'her...', 'algorithms.', 'itulah', 'e-mails', 'format', 'hell', 'fosdem', 'lie']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "print (list(input_vocab_to_int.keys())[:20])\n",
    "print (list(input_int_to_vocab.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<EOS>', '<UNK>', '<GO>', 'produced', 'lays', 'zef', 'despert√©', 'va', 'tos', 'felicitaciones', 'emotions.', 'specifically', 'pada', 'room.', 'format', 'fosdem', 'driving', 'worry,', 'softwares']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "print (list(output_vocab_to_int.keys())[:20])\n",
    "print (list(output_int_to_vocab.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_ids(input_text, output_text, input_vocab_to_int, output_vocab_to_int):   \n",
    "    \n",
    "    input_ids = [[input_vocab_to_int[word] for word in sentence.split()]\n",
    "                      for sentence in input_text.split(\"\\n\")]\n",
    "    \n",
    "    output_ids = [[output_vocab_to_int[word] for word in sentence.split()] + [output_vocab_to_int[\"<EOS>\"]]\n",
    "                      for sentence in output_text.split(\"\\n\")]\n",
    "    \n",
    "    return input_ids, output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_ids, output_ids = text_to_ids(input_text, output_text, input_vocab_to_int, output_vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[318], [4053, 871, 3411, 2292, 2577, 3132, 888, 234, 81, 4196, 2775, 854], [929, 2191, 3952, 1492, 3303, 3344, 1931, 3862, 2536, 4281, 3045], [929, 3628, 2090, 1058, 4185, 3952, 3569, 3344], [888, 1539, 1682, 3578, 3952, 477, 1931, 1701, 2467, 904, 3344]]\n",
      "[[1907, 422, 863, 3709, 3665, 3163, 3089, 110, 1], [3985, 3405, 826, 1718, 3163, 1], [2600, 2060, 826, 1279, 836, 3665, 1755, 3953, 3571, 3678, 3375, 1154, 923, 3419, 2044, 2439, 736, 1755, 2122, 1953, 993, 3163, 1], [2044, 3889, 3357, 3163, 836, 3342, 1896, 433, 3746, 1356, 1295, 3807, 700, 1], [2894, 1364, 1682, 1641, 2146, 1248, 2620, 1168, 73, 1359, 2972, 1]]\n"
     ]
    }
   ],
   "source": [
    "print (inputs_ids[:5])\n",
    "print (output_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: No GPU found. Please use a GPU to train your neural network.\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "#assert LooseVersion(tf.__version__) in [LooseVersion('1.0.0'), LooseVersion('1.0.1')], 'This project requires TensorFlow version 1.0  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    inputs = tf.placeholder(tf.int32, (None, None), name = \"input\")\n",
    "    targets = tf.placeholder(tf.int32, (None, None), name=\"targets\")\n",
    "    learning_rate = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "    keep_probability = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "    \n",
    "    return inputs, targets, learning_rate, keep_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_decoding_input(target_data, target_vocab_to_int, batch_size):\n",
    "    go = target_vocab_to_int['<GO>']\n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    targets = tf.concat([tf.fill([batch_size, 1], go), ending], 1)\n",
    "    \n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob):    \n",
    "    basic_lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    dropout = tf.contrib.rnn.DropoutWrapper(basic_lstm, keep_prob)\n",
    "    rnn_cell = tf.contrib.rnn.MultiRNNCell([basic_lstm] * num_layers)\n",
    "    \n",
    "    _, state = tf.nn.dynamic_rnn(rnn_cell, rnn_inputs, dtype=tf.float32)\n",
    "           \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer_train(encoder_state, dec_cell, dec_embed_input, sequence_length, decoding_scope,\n",
    "                         output_fn, keep_prob):\n",
    "\n",
    "    train_fn = tf.contrib.seq2seq.simple_decoder_fn_train(encoder_state)\n",
    "    train_pred, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(\n",
    "                        cell = dec_cell, \n",
    "                        decoder_fn = train_fn, \n",
    "                        inputs = dec_embed_input,\n",
    "                        sequence_length = sequence_length,\n",
    "                        scope = decoding_scope)\n",
    "    \n",
    "    logits = output_fn(train_pred)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id,\n",
    "                         maximum_length, vocab_size, decoding_scope, output_fn, keep_prob):\n",
    "\n",
    "    infer_decoder_fn  = tf.contrib.seq2seq.simple_decoder_fn_inference(\n",
    "                output_fn = output_fn,\n",
    "                encoder_state = encoder_state,\n",
    "                embeddings = dec_embeddings,\n",
    "                start_of_sequence_id = start_of_sequence_id,\n",
    "                end_of_sequence_id = end_of_sequence_id,\n",
    "                maximum_length = maximum_length,\n",
    "                num_decoder_symbols = vocab_size)\n",
    "    \n",
    "    infer_logits, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(\n",
    "                            cell = dec_cell,\n",
    "                            decoder_fn = infer_decoder_fn,\n",
    "                           scope = decoding_scope)\n",
    "    \n",
    "    return infer_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer(dec_embed_input, dec_embeddings, encoder_state, vocab_size, sequence_length, rnn_size,\n",
    "                   num_layers, target_vocab_to_int, keep_prob):\n",
    "    \n",
    "    basic_lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    dropout = tf.contrib.rnn.DropoutWrapper(basic_lstm, keep_prob)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([basic_lstm] * num_layers)\n",
    "    \n",
    "    with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "        output_fn = (lambda x: tf.contrib.layers.fully_connected(x, vocab_size, None, scope = decoding_scope))\n",
    "        \n",
    "    with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "        training_logits = decoding_layer_train(encoder_state, cell, dec_embed_input,\n",
    "                                            sequence_length, decoding_scope, output_fn, keep_prob)\n",
    "    \n",
    "    with tf.variable_scope(\"decoding\", reuse=True) as decoding_scope:    \n",
    "        inference_logits = decoding_layer_infer(encoder_state, cell, dec_embeddings, target_vocab_to_int['<GO>'],\n",
    "                                                target_vocab_to_int['<EOS>'], sequence_length - 1 , vocab_size,\n",
    "                                                decoding_scope, output_fn, keep_prob)\n",
    "    \n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size, sequence_length, source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size, rnn_size, num_layers, target_vocab_to_int):\n",
    "\n",
    "    enc_embed_input = tf.contrib.layers.embed_sequence(input_data, source_vocab_size, enc_embedding_size)\n",
    "    encoder_state = encoding_layer(enc_embed_input, rnn_size, num_layers, keep_prob)\n",
    "\n",
    "    dec_inputs = process_decoding_input(target_data, target_vocab_to_int, batch_size)\n",
    "    dec_embeddings = tf.Variable(tf.truncated_normal([target_vocab_size, dec_embedding_size], stddev = 0.01))\n",
    "    dec_embed_inputs = tf.nn.embedding_lookup(dec_embeddings, dec_inputs)\n",
    "        \n",
    "    train_logits, infer_logits = decoding_layer(\n",
    "                               dec_embed_input = dec_embed_inputs,\n",
    "                               dec_embeddings = dec_embeddings,\n",
    "                               encoder_state = encoder_state,\n",
    "                               vocab_size = target_vocab_size,\n",
    "                               sequence_length = sequence_length,\n",
    "                               rnn_size = rnn_size,\n",
    "                               num_layers = num_layers,\n",
    "                               target_vocab_to_int = target_vocab_to_int,\n",
    "                               keep_prob = keep_prob)\n",
    "    \n",
    "    return train_logits, infer_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "batch_size = 256\n",
    "rnn_size = 512\n",
    "num_layers = 2\n",
    "encoding_embedding_size = 13\n",
    "decoding_embedding_size = 13\n",
    "learning_rate = 0.001\n",
    "keep_probability = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x10aa91550> with a different variable scope than its first use.  First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f1931035a375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     train_logits, inference_logits = seq2seq_model(\n\u001b[1;32m     11\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vocab_to_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_vocab_to_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         encoding_embedding_size, decoding_embedding_size, rnn_size, num_layers, output_vocab_to_int)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'logits'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-8d0fe992484e>\u001b[0m in \u001b[0;36mseq2seq_model\u001b[0;34m(input_data, target_data, keep_prob, batch_size, sequence_length, source_vocab_size, target_vocab_size, enc_embedding_size, dec_embedding_size, rnn_size, num_layers, target_vocab_to_int)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0menc_embed_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_embedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mencoder_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_embed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdec_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_decoding_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vocab_to_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-565f1524ae87>\u001b[0m in \u001b[0;36mencoding_layer\u001b[0;34m(rnn_inputs, rnn_size, num_layers, keep_prob)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrnn_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiRNNCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbasic_lstm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    718\u001b[0m       \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[1;32m   2621\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2454\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2455\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2456\u001b[0;31m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2404\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m-> 2406\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2408\u001b[0m       \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    703\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    704\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0;31m# Pack state if using state tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    951\u001b[0m                 state, [0, cur_state_pos], [-1, cell.state_size])\n\u001b[1;32m    952\u001b[0m             \u001b[0mcur_state_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m           \u001b[0mcur_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m           \u001b[0mnew_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m     new_states = (tuple(new_states) if self._state_is_tuple else\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;34m\"\"\"Long short-term memory cell (LSTM).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_checked_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"basic_lstm_cell\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m       \u001b[0;31m# Parameters of gates are concatenated into one multiply for efficiency.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_is_tuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\u001b[0m in \u001b[0;36m_checked_scope\u001b[0;34m(cell, scope, reuse, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;34m\"this error will remain until then.)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             % (cell, cell_scope.name, scope_name, type(cell).__name__,\n\u001b[0;32m---> 77\u001b[0;31m                type(cell).__name__))\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0mweights_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x10aa91550> with a different variable scope than its first use.  First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)"
     ]
    }
   ],
   "source": [
    "save_path = 'checkpoints/dev'\n",
    "max_source_sentence_length = max([len(sentence) for sentence in inputs_ids])\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, targets, lr, keep_prob = model_inputs()\n",
    "    sequence_length = tf.placeholder_with_default(max_source_sentence_length, None, name='sequence_length')\n",
    "    input_shape = tf.shape(input_data)\n",
    "    \n",
    "    train_logits, inference_logits = seq2seq_model(\n",
    "        tf.reverse(input_data, [-1]), targets, keep_prob, batch_size, sequence_length, len(input_vocab_to_int), len(output_vocab_to_int),\n",
    "        encoding_embedding_size, decoding_embedding_size, rnn_size, num_layers, output_vocab_to_int)\n",
    "\n",
    "    tf.identity(inference_logits, 'logits')\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            train_logits,\n",
    "            targets,\n",
    "            tf.ones([input_shape[0], sequence_length]))\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch):\n",
    "    \"\"\"\n",
    "    Pad sentence with <PAD> id\n",
    "    \"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [CODES['<PAD>']] * (max_sentence - len(sentence))\n",
    "            for sentence in sentence_batch]\n",
    "\n",
    "def batch_data(source, target, batch_size):\n",
    "    \"\"\"\n",
    "    Batch source and target together\n",
    "    \"\"\"\n",
    "    for batch_i in range(0, len(source)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        source_batch = source[start_i:start_i + batch_size]\n",
    "        target_batch = target[start_i:start_i + batch_size]\n",
    "        yield np.array(pad_sentence_batch(source_batch)), np.array(pad_sentence_batch(target_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1]), (0,0)],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, np.argmax(logits, 2)))\n",
    "\n",
    "train_source = inputs_ids[batch_size:]\n",
    "train_target = output_ids[batch_size:]\n",
    "\n",
    "valid_source = pad_sentence_batch(inputs_ids[:batch_size])\n",
    "valid_target = pad_sentence_batch(output_ids[:batch_size])\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        for batch_i, (source_batch, target_batch) in enumerate(batch_data(train_source, train_target, batch_size)):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: source_batch,\n",
    "                 targets: target_batch,\n",
    "                 lr: learning_rate,\n",
    "                 sequence_length: target_batch.shape[1],\n",
    "                 keep_prob: keep_probability})\n",
    "            \n",
    "            batch_train_logits = sess.run(\n",
    "                inference_logits,\n",
    "                {input_data: source_batch, keep_prob: 1.0})\n",
    "            batch_valid_logits = sess.run(\n",
    "                inference_logits,\n",
    "                {input_data: valid_source, keep_prob: 1.0})\n",
    "                \n",
    "            train_acc = get_accuracy(target_batch, batch_train_logits)\n",
    "            valid_acc = get_accuracy(np.array(valid_target), batch_valid_logits)\n",
    "            end_time = time.time()\n",
    "            print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.3f}, Validation Accuracy: {:>6.3f}, Loss: {:>6.3f}'\n",
    "                  .format(epoch_i, batch_i, len(inputs_ids) // batch_size, train_acc, valid_acc, loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
